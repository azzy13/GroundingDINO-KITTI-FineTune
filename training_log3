world size: 2, rank: 1, local rank: 1
{
  "SHELL": "/bin/bash",
  "COLORTERM": "truecolor",
  "TERM_PROGRAM_VERSION": "1.105.0",
  "CONDA_EXE": "/isis/home/hasana3/miniconda3/bin/conda",
  "_CE_M": "",
  "TERMCAP": "SC|screen.xterm-256color|VT 100/ANSI X3.64 virtual terminal:DO=\\E[%dB:LE=\\E[%dD:RI=\\E[%dC:UP=\\E[%dA:bs:bt=\\E[Z:cd=\\E[J:ce=\\E[K:cl=\\E[H\\E[J:cm=\\E[%i%d;%dH:ct=\\E[3g:do=^J:nd=\\E[C:pt:rc=\\E8:rs=\\Ec:sc=\\E7:st=\\EH:up=\\EM:le=^H:bl=^G:cr=^M:it#8:ho=\\E[H:nw=\\EE:ta=^I:is=\\E)0:li#10:co#79:am:xn:xv:LP:sr=\\EM:al=\\E[L:AL=\\E[%dL:cs=\\E[%i%d;%dr:dl=\\E[M:DL=\\E[%dM:dc=\\E[P:DC=\\E[%dP:im=\\E[4h:ei=\\E[4l:mi:IC=\\E[%d@:ks=\\E[?1h\\E=:ke=\\E[?1l\\E>:vi=\\E[?25l:ve=\\E[34h\\E[?25h:vs=\\E[34l:ti=\\E[?1049h:te=\\E[?1049l:us=\\E[4m:ue=\\E[24m:so=\\E[3m:se=\\E[23m:mb=\\E[5m:md=\\E[1m:mh=\\E[2m:mr=\\E[7m:me=\\E[m:ms:Co#8:pa#64:AF=\\E[3%dm:AB=\\E[4%dm:op=\\E[39;49m:AX:vb=\\Eg:G0:as=\\E(0:ae=\\E(B:ac=\\140\\140aaffggjjkkllmmnnooppqqrrssttuuvvwwxxyyzz{{||}}~~..--++,,hhII00:po=\\E[5i:pf=\\E[4i:Km=\\E[<:k0=\\E[10~:k1=\\EOP:k2=\\EOQ:k3=\\EOR:k4=\\EOS:k5=\\E[15~:k6=\\E[17~:k7=\\E[18~:k8=\\E[19~:k9=\\E[20~:k;=\\E[21~:F1=\\E[23~:F2=\\E[24~:kB=\\E[Z:kh=\\E[1~:@1=\\E[1~:kH=\\E[4~:@7=\\E[4~:kN=\\E[6~:kP=\\E[5~:kI=\\E[2~:kD=\\E[3~:ku=\\EOA:kd=\\EOB:kr=\\EOC:kl=\\EOD:km:",
  "WINDOW": "0",
  "PWD": "/isis/home/hasana3/Open-GroundingDino",
  "LOGNAME": "hasana3",
  "XDG_SESSION_TYPE": "tty",
  "CONDA_PREFIX": "/isis/home/hasana3/miniconda3/envs/dino_train",
  "VSCODE_GIT_ASKPASS_NODE": "/isis/home/hasana3/.vscode-server/bin/03c265b1adee71ac88f833e065f7bb956b60550a/node",
  "MOTD_SHOWN": "pam",
  "TOKENIZERS_PARALLELISM": "false",
  "HOME": "/isis/home/hasana3",
  "LANG": "en_US.UTF-8",
  "LS_COLORS": "rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.zst=01;31:*.tzst=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.wim=01;31:*.swm=01;31:*.dwm=01;31:*.esd=01;31:*.jpg=01;35:*.jpeg=01;35:*.mjpg=01;35:*.mjpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.webp=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36:",
  "CONDA_PROMPT_MODIFIER": "(dino_train) ",
  "GIT_ASKPASS": "/isis/home/hasana3/.vscode-server/bin/03c265b1adee71ac88f833e065f7bb956b60550a/extensions/git/dist/askpass.sh",
  "SSH_CONNECTION": "10.52.136.200 52980 10.2.218.246 22",
  "VSCODE_GIT_ASKPASS_EXTRA_ARGS": "",
  "CUDA_VISIBLE_DEVICES": "0,1",
  "VSCODE_PYTHON_AUTOACTIVATE_GUARD": "1",
  "XDG_SESSION_CLASS": "user",
  "PYTHONPATH": "/isis/home/hasana3/Open-GroundingDino/:",
  "TERM": "screen.xterm-256color",
  "_CE_CONDA": "",
  "USER": "hasana3",
  "VSCODE_GIT_IPC_HANDLE": "/run/user/20007/vscode-git-3a0aeed79a.sock",
  "CONDA_SHLVL": "1",
  "SHLVL": "3",
  "XDG_SESSION_ID": "1",
  "CONDA_PYTHON_EXE": "/isis/home/hasana3/miniconda3/bin/python",
  "LD_LIBRARY_PATH": "/usr/lib/nvidia-cuda-toolkit/lib64:/usr/lib/nvidia-cuda-toolkit/lib64:/usr/lib/nvidia-cuda-toolkit/lib64:",
  "XDG_RUNTIME_DIR": "/run/user/20007",
  "SSH_CLIENT": "10.52.136.200 52980 22",
  "CONDA_DEFAULT_ENV": "dino_train",
  "LC_ALL": "en_US.UTF-8",
  "VSCODE_GIT_ASKPASS_MAIN": "/isis/home/hasana3/.vscode-server/bin/03c265b1adee71ac88f833e065f7bb956b60550a/extensions/git/dist/askpass-main.js",
  "CUDA_HOME": "/usr/lib/nvidia-cuda-toolkit",
  "XDG_DATA_DIRS": "/usr/share/gnome:/usr/local/share:/usr/share:/var/lib/snapd/desktop",
  "BROWSER": "/isis/home/hasana3/.vscode-server/bin/03c265b1adee71ac88f833e065f7bb956b60550a/bin/helpers/browser.sh",
  "PATH": "/isis/home/hasana3/miniconda3/envs/dino_train/bin:/usr/lib/nvidia-cuda-toolkit/bin:/opt/ros/humble/bin:/usr/lib/nvidia-cuda-toolkit/bin:/opt/ros/humble/bin:/isis/home/hasana3/.vscode-server/bin/03c265b1adee71ac88f833e065f7bb956b60550a/bin/remote-cli:/isis/home/hasana3/.local/bin:/usr/lib/nvidia-cuda-toolkit/bin:/isis/home/hasana3/miniconda3/condabin:/opt/ros/humble/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/isis/home/hasana3/.vscode-server/data/User/globalStorage/github.copilot-chat/debugCommand",
  "STY": "4135.traindino",
  "DBUS_SESSION_BUS_ADDRESS": "unix:path=/run/user/20007/bus",
  "OLDPWD": "/isis/home/hasana3/Open-GroundingDino",
  "TERM_PROGRAM": "vscode",
  "VSCODE_IPC_HOOK_CLI": "/run/user/20007/vscode-ipc-7a16d535-b101-4d4a-939e-bf6bd133df09.sock",
  "_": "/isis/home/hasana3/miniconda3/envs/dino_train/bin/python",
  "OMP_NUM_THREADS": "1",
  "LOCAL_RANK": "1",
  "RANK": "1",
  "GROUP_RANK": "0",
  "ROLE_RANK": "1",
  "ROLE_NAME": "default",
  "LOCAL_WORLD_SIZE": "2",
  "WORLD_SIZE": "2",
  "GROUP_WORLD_SIZE": "1",
  "ROLE_WORLD_SIZE": "2",
  "MASTER_ADDR": "127.0.0.1",
  "MASTER_PORT": "29500",
  "TORCHELASTIC_RESTART_COUNT": "0",
  "TORCHELASTIC_MAX_RESTARTS": "0",
  "TORCHELASTIC_RUN_ID": "none",
  "TORCHELASTIC_USE_AGENT_STORE": "True",
  "NCCL_ASYNC_ERROR_HANDLING": "1",
  "TORCHELASTIC_ERROR_FILE": "/tmp/torchelastic_c16jcgmg/none_5bz17n0q/attempt_0/1/error.json"
}
world size: 2, rank: 0, local rank: 0
{
  "SHELL": "/bin/bash",
  "COLORTERM": "truecolor",
  "TERM_PROGRAM_VERSION": "1.105.0",
  "CONDA_EXE": "/isis/home/hasana3/miniconda3/bin/conda",
  "_CE_M": "",
  "TERMCAP": "SC|screen.xterm-256color|VT 100/ANSI X3.64 virtual terminal:DO=\\E[%dB:LE=\\E[%dD:RI=\\E[%dC:UP=\\E[%dA:bs:bt=\\E[Z:cd=\\E[J:ce=\\E[K:cl=\\E[H\\E[J:cm=\\E[%i%d;%dH:ct=\\E[3g:do=^J:nd=\\E[C:pt:rc=\\E8:rs=\\Ec:sc=\\E7:st=\\EH:up=\\EM:le=^H:bl=^G:cr=^M:it#8:ho=\\E[H:nw=\\EE:ta=^I:is=\\E)0:li#10:co#79:am:xn:xv:LP:sr=\\EM:al=\\E[L:AL=\\E[%dL:cs=\\E[%i%d;%dr:dl=\\E[M:DL=\\E[%dM:dc=\\E[P:DC=\\E[%dP:im=\\E[4h:ei=\\E[4l:mi:IC=\\E[%d@:ks=\\E[?1h\\E=:ke=\\E[?1l\\E>:vi=\\E[?25l:ve=\\E[34h\\E[?25h:vs=\\E[34l:ti=\\E[?1049h:te=\\E[?1049l:us=\\E[4m:ue=\\E[24m:so=\\E[3m:se=\\E[23m:mb=\\E[5m:md=\\E[1m:mh=\\E[2m:mr=\\E[7m:me=\\E[m:ms:Co#8:pa#64:AF=\\E[3%dm:AB=\\E[4%dm:op=\\E[39;49m:AX:vb=\\Eg:G0:as=\\E(0:ae=\\E(B:ac=\\140\\140aaffggjjkkllmmnnooppqqrrssttuuvvwwxxyyzz{{||}}~~..--++,,hhII00:po=\\E[5i:pf=\\E[4i:Km=\\E[<:k0=\\E[10~:k1=\\EOP:k2=\\EOQ:k3=\\EOR:k4=\\EOS:k5=\\E[15~:k6=\\E[17~:k7=\\E[18~:k8=\\E[19~:k9=\\E[20~:k;=\\E[21~:F1=\\E[23~:F2=\\E[24~:kB=\\E[Z:kh=\\E[1~:@1=\\E[1~:kH=\\E[4~:@7=\\E[4~:kN=\\E[6~:kP=\\E[5~:kI=\\E[2~:kD=\\E[3~:ku=\\EOA:kd=\\EOB:kr=\\EOC:kl=\\EOD:km:",
  "WINDOW": "0",
  "PWD": "/isis/home/hasana3/Open-GroundingDino",
  "LOGNAME": "hasana3",
  "XDG_SESSION_TYPE": "tty",
  "CONDA_PREFIX": "/isis/home/hasana3/miniconda3/envs/dino_train",
  "VSCODE_GIT_ASKPASS_NODE": "/isis/home/hasana3/.vscode-server/bin/03c265b1adee71ac88f833e065f7bb956b60550a/node",
  "MOTD_SHOWN": "pam",
  "TOKENIZERS_PARALLELISM": "false",
  "HOME": "/isis/home/hasana3",
  "LANG": "en_US.UTF-8",
  "LS_COLORS": "rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.zst=01;31:*.tzst=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.wim=01;31:*.swm=01;31:*.dwm=01;31:*.esd=01;31:*.jpg=01;35:*.jpeg=01;35:*.mjpg=01;35:*.mjpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.webp=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36:",
  "CONDA_PROMPT_MODIFIER": "(dino_train) ",
  "GIT_ASKPASS": "/isis/home/hasana3/.vscode-server/bin/03c265b1adee71ac88f833e065f7bb956b60550a/extensions/git/dist/askpass.sh",
  "SSH_CONNECTION": "10.52.136.200 52980 10.2.218.246 22",
  "VSCODE_GIT_ASKPASS_EXTRA_ARGS": "",
  "CUDA_VISIBLE_DEVICES": "0,1",
  "VSCODE_PYTHON_AUTOACTIVATE_GUARD": "1",
  "XDG_SESSION_CLASS": "user",
  "PYTHONPATH": "/isis/home/hasana3/Open-GroundingDino/:",
  "TERM": "screen.xterm-256color",
  "_CE_CONDA": "",
  "USER": "hasana3",
  "VSCODE_GIT_IPC_HANDLE": "/run/user/20007/vscode-git-3a0aeed79a.sock",
  "CONDA_SHLVL": "1",
  "SHLVL": "3",
  "XDG_SESSION_ID": "1",
  "CONDA_PYTHON_EXE": "/isis/home/hasana3/miniconda3/bin/python",
  "LD_LIBRARY_PATH": "/usr/lib/nvidia-cuda-toolkit/lib64:/usr/lib/nvidia-cuda-toolkit/lib64:/usr/lib/nvidia-cuda-toolkit/lib64:",
  "XDG_RUNTIME_DIR": "/run/user/20007",
  "SSH_CLIENT": "10.52.136.200 52980 22",
  "CONDA_DEFAULT_ENV": "dino_train",
  "LC_ALL": "en_US.UTF-8",
  "VSCODE_GIT_ASKPASS_MAIN": "/isis/home/hasana3/.vscode-server/bin/03c265b1adee71ac88f833e065f7bb956b60550a/extensions/git/dist/askpass-main.js",
  "CUDA_HOME": "/usr/lib/nvidia-cuda-toolkit",
  "XDG_DATA_DIRS": "/usr/share/gnome:/usr/local/share:/usr/share:/var/lib/snapd/desktop",
  "BROWSER": "/isis/home/hasana3/.vscode-server/bin/03c265b1adee71ac88f833e065f7bb956b60550a/bin/helpers/browser.sh",
  "PATH": "/isis/home/hasana3/miniconda3/envs/dino_train/bin:/usr/lib/nvidia-cuda-toolkit/bin:/opt/ros/humble/bin:/usr/lib/nvidia-cuda-toolkit/bin:/opt/ros/humble/bin:/isis/home/hasana3/.vscode-server/bin/03c265b1adee71ac88f833e065f7bb956b60550a/bin/remote-cli:/isis/home/hasana3/.local/bin:/usr/lib/nvidia-cuda-toolkit/bin:/isis/home/hasana3/miniconda3/condabin:/opt/ros/humble/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/isis/home/hasana3/.vscode-server/data/User/globalStorage/github.copilot-chat/debugCommand",
  "STY": "4135.traindino",
  "DBUS_SESSION_BUS_ADDRESS": "unix:path=/run/user/20007/bus",
  "OLDPWD": "/isis/home/hasana3/Open-GroundingDino",
  "TERM_PROGRAM": "vscode",
  "VSCODE_IPC_HOOK_CLI": "/run/user/20007/vscode-ipc-7a16d535-b101-4d4a-939e-bf6bd133df09.sock",
  "_": "/isis/home/hasana3/miniconda3/envs/dino_train/bin/python",
  "OMP_NUM_THREADS": "1",
  "LOCAL_RANK": "0",
  "RANK": "0",
  "GROUP_RANK": "0",
  "ROLE_RANK": "0",
  "ROLE_NAME": "default",
  "LOCAL_WORLD_SIZE": "2",
  "WORLD_SIZE": "2",
  "GROUP_WORLD_SIZE": "1",
  "ROLE_WORLD_SIZE": "2",
  "MASTER_ADDR": "127.0.0.1",
  "MASTER_PORT": "29500",
  "TORCHELASTIC_RESTART_COUNT": "0",
  "TORCHELASTIC_MAX_RESTARTS": "0",
  "TORCHELASTIC_RUN_ID": "none",
  "TORCHELASTIC_USE_AGENT_STORE": "True",
  "NCCL_ASYNC_ERROR_HANDLING": "1",
  "TORCHELASTIC_ERROR_FILE": "/tmp/torchelastic_c16jcgmg/none_5bz17n0q/attempt_0/0/error.json"
}
  == distributed init (rank 0) done.
  == distributed init (rank 1) done.Loading config file from config/GroundingDINO_SwinB_cfg.py

[32mINFO    [0m [32m2025-10-24 02:05:30,209 | [34mgit:
  sha: 03040d37d4ba3939321abac882ae6c65a7cf42db, status: has uncommited changes, branch: main
[0m
[32mINFO    [0m [32m2025-10-24 02:05:30,210 | [34mCommand: main.py --local_rank=0 -c config/GroundingDINO_SwinB_cfg.py --datasets dataset_meta_kitti.json --output_dir ../vlmtest/GroundingDINO/output/kitti_swinb_finetune --pretrain_model_path ../vlmtest/GroundingDINO/weights/groundingdino_swinb_cogcoor.pth --num_workers 32 --options lr=1e-4 batch_size=8 epochs=100 use_coco_eval=False[0m
[32mINFO    [0m [32m2025-10-24 02:05:30,211 | [34mFull config saved to ../vlmtest/GroundingDINO/output/kitti_swinb_finetune/config_args_all.json[0m
[32mINFO    [0m [32m2025-10-24 02:05:30,211 | [34mworld size: 2[0m
[32mINFO    [0m [32m2025-10-24 02:05:30,211 | [34mrank: 0[0m
[32mINFO    [0m [32m2025-10-24 02:05:30,211 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2025-10-24 02:05:30,211 | [34margs: Namespace(config_file='config/GroundingDINO_SwinB_cfg.py', options={'lr': 0.0001, 'batch_size': 8, 'epochs': 100, 'use_coco_eval': False}, datasets='dataset_meta_kitti.json', remove_difficult=False, fix_size=False, output_dir='../vlmtest/GroundingDINO/output/kitti_swinb_finetune', note='', device='cuda', seed=42, resume='', pretrain_model_path='../vlmtest/GroundingDINO/weights/groundingdino_swinb_cogcoor.pth', finetune_ignore=None, start_epoch=0, eval=False, num_workers=32, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=2, dist_url='env://', rank=0, local_rank=0, amp=False, gpu=0, distributed=True, dist_backend='nccl', batch_size=8, modelname='groundingdino', backbone='swin_B_384_22k', position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, num_feature_levels=4, enc_n_points=4, dec_n_points=4, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, transformer_activation='relu', dec_pred_bbox_embed_share=True, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, dn_label_coef=1.0, dn_bbox_coef=1.0, embed_init_tgt=True, dn_labelbook_size=2000, max_text_len=256, text_encoder_type='bert-base-uncased', use_text_enhancer=True, use_fusion_layer=True, use_checkpoint=True, use_transformer_ckpt=True, use_text_cross_attention=True, text_dropout=0.0, fusion_dropout=0.0, fusion_droppath=0.1, sub_sentence_present=True, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, max_labels=50, lr=0.0001, freeze_keywords=['bert'], lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], weight_decay=0.0001, param_dict_type='ddetr_in_mmdet', ddetr_lr_param=False, epochs=100, lr_drop=4, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[4, 8], frozen_weights=None, dilation=False, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=1.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=2.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, mask_loss_coef=1.0, dice_loss_coef=1.0, focal_alpha=0.25, focal_gamma=2.0, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_class_embed_share=True, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, use_coco_eval=False, dn_scalar=100, label_list=['car', 'pedestrian'])
[0m
[36mDEBUG   [0m [36m2025-10-24 02:05:30,212 | [34mbuild model ... ...[0m
final text_encoder_type: bert-base-uncased
load tokenizer done.
final text_encoder_type: bert-base-uncased
load tokenizer done.
[36mDEBUG   [0m [36m2025-10-24 02:05:32,007 | [34mbuild model, done.[0m
[32mINFO    [0m [32m2025-10-24 02:05:32,046 | [34mnumber of params:232313216[0m
[32mINFO    [0m [32m2025-10-24 02:05:32,048 | [34mparams before freezing:
{
  "module.transformer.level_embed": 1024,
  "module.transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.0.norm1.weight": 256,
  "module.transformer.encoder.layers.0.norm1.bias": 256,
  "module.transformer.encoder.layers.0.linear1.weight": 524288,
  "module.transformer.encoder.layers.0.linear1.bias": 2048,
  "module.transformer.encoder.layers.0.linear2.weight": 524288,
  "module.transformer.encoder.layers.0.linear2.bias": 256,
  "module.transformer.encoder.layers.0.norm2.weight": 256,
  "module.transformer.encoder.layers.0.norm2.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.1.norm1.weight": 256,
  "module.transformer.encoder.layers.1.norm1.bias": 256,
  "module.transformer.encoder.layers.1.linear1.weight": 524288,
  "module.transformer.encoder.layers.1.linear1.bias": 2048,
  "module.transformer.encoder.layers.1.linear2.weight": 524288,
  "module.transformer.encoder.layers.1.linear2.bias": 256,
  "module.transformer.encoder.layers.1.norm2.weight": 256,
  "module.transformer.encoder.layers.1.norm2.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.2.norm1.weight": 256,
  "module.transformer.encoder.layers.2.norm1.bias": 256,
  "module.transformer.encoder.layers.2.linear1.weight": 524288,
  "module.transformer.encoder.layers.2.linear1.bias": 2048,
  "module.transformer.encoder.layers.2.linear2.weight": 524288,
  "module.transformer.encoder.layers.2.linear2.bias": 256,
  "module.transformer.encoder.layers.2.norm2.weight": 256,
  "module.transformer.encoder.layers.2.norm2.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.3.norm1.weight": 256,
  "module.transformer.encoder.layers.3.norm1.bias": 256,
  "module.transformer.encoder.layers.3.linear1.weight": 524288,
  "module.transformer.encoder.layers.3.linear1.bias": 2048,
  "module.transformer.encoder.layers.3.linear2.weight": 524288,
  "module.transformer.encoder.layers.3.linear2.bias": 256,
  "module.transformer.encoder.layers.3.norm2.weight": 256,
  "module.transformer.encoder.layers.3.norm2.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.4.norm1.weight": 256,
  "module.transformer.encoder.layers.4.norm1.bias": 256,
  "module.transformer.encoder.layers.4.linear1.weight": 524288,
  "module.transformer.encoder.layers.4.linear1.bias": 2048,
  "module.transformer.encoder.layers.4.linear2.weight": 524288,
  "module.transformer.encoder.layers.4.linear2.bias": 256,
  "module.transformer.encoder.layers.4.norm2.weight": 256,
  "module.transformer.encoder.layers.4.norm2.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.5.norm1.weight": 256,
  "module.transformer.encoder.layers.5.norm1.bias": 256,
  "module.transformer.encoder.layers.5.linear1.weight": 524288,
  "module.transformer.encoder.layers.5.linear1.bias": 2048,
  "module.transformer.encoder.layers.5.linear2.weight": 524288,
  "module.transformer.encoder.layers.5.linear2.bias": 256,
  "module.transformer.encoder.layers.5.norm2.weight": 256,
  "module.transformer.encoder.layers.5.norm2.bias": 256,
  "module.transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.0.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.0.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.0.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.0.linear2.bias": 256,
  "module.transformer.encoder.text_layers.0.norm1.weight": 256,
  "module.transformer.encoder.text_layers.0.norm1.bias": 256,
  "module.transformer.encoder.text_layers.0.norm2.weight": 256,
  "module.transformer.encoder.text_layers.0.norm2.bias": 256,
  "module.transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.1.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.1.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.1.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.1.linear2.bias": 256,
  "module.transformer.encoder.text_layers.1.norm1.weight": 256,
  "module.transformer.encoder.text_layers.1.norm1.bias": 256,
  "module.transformer.encoder.text_layers.1.norm2.weight": 256,
  "module.transformer.encoder.text_layers.1.norm2.bias": 256,
  "module.transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.2.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.2.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.2.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.2.linear2.bias": 256,
  "module.transformer.encoder.text_layers.2.norm1.weight": 256,
  "module.transformer.encoder.text_layers.2.norm1.bias": 256,
  "module.transformer.encoder.text_layers.2.norm2.weight": 256,
  "module.transformer.encoder.text_layers.2.norm2.bias": 256,
  "module.transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.3.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.3.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.3.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.3.linear2.bias": 256,
  "module.transformer.encoder.text_layers.3.norm1.weight": 256,
  "module.transformer.encoder.text_layers.3.norm1.bias": 256,
  "module.transformer.encoder.text_layers.3.norm2.weight": 256,
  "module.transformer.encoder.text_layers.3.norm2.bias": 256,
  "module.transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.4.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.4.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.4.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.4.linear2.bias": 256,
  "module.transformer.encoder.text_layers.4.norm1.weight": 256,
  "module.transformer.encoder.text_layers.4.norm1.bias": 256,
  "module.transformer.encoder.text_layers.4.norm2.weight": 256,
  "module.transformer.encoder.text_layers.4.norm2.bias": 256,
  "module.transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.5.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.5.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.5.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.5.linear2.bias": 256,
  "module.transformer.encoder.text_layers.5.norm1.weight": 256,
  "module.transformer.encoder.text_layers.5.norm1.bias": 256,
  "module.transformer.encoder.text_layers.5.norm2.weight": 256,
  "module.transformer.encoder.text_layers.5.norm2.bias": 256,
  "module.transformer.encoder.fusion_layers.0.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.0.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.1.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.1.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.2.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.2.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.3.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.3.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.4.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.4.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.5.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.5.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.0.norm1.weight": 256,
  "module.transformer.decoder.layers.0.norm1.bias": 256,
  "module.transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.0.catext_norm.weight": 256,
  "module.transformer.decoder.layers.0.catext_norm.bias": 256,
  "module.transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.0.norm2.weight": 256,
  "module.transformer.decoder.layers.0.norm2.bias": 256,
  "module.transformer.decoder.layers.0.linear1.weight": 524288,
  "module.transformer.decoder.layers.0.linear1.bias": 2048,
  "module.transformer.decoder.layers.0.linear2.weight": 524288,
  "module.transformer.decoder.layers.0.linear2.bias": 256,
  "module.transformer.decoder.layers.0.norm3.weight": 256,
  "module.transformer.decoder.layers.0.norm3.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.1.norm1.weight": 256,
  "module.transformer.decoder.layers.1.norm1.bias": 256,
  "module.transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.1.catext_norm.weight": 256,
  "module.transformer.decoder.layers.1.catext_norm.bias": 256,
  "module.transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.1.norm2.weight": 256,
  "module.transformer.decoder.layers.1.norm2.bias": 256,
  "module.transformer.decoder.layers.1.linear1.weight": 524288,
  "module.transformer.decoder.layers.1.linear1.bias": 2048,
  "module.transformer.decoder.layers.1.linear2.weight": 524288,
  "module.transformer.decoder.layers.1.linear2.bias": 256,
  "module.transformer.decoder.layers.1.norm3.weight": 256,
  "module.transformer.decoder.layers.1.norm3.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.2.norm1.weight": 256,
  "module.transformer.decoder.layers.2.norm1.bias": 256,
  "module.transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.2.catext_norm.weight": 256,
  "module.transformer.decoder.layers.2.catext_norm.bias": 256,
  "module.transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.2.norm2.weight": 256,
  "module.transformer.decoder.layers.2.norm2.bias": 256,
  "module.transformer.decoder.layers.2.linear1.weight": 524288,
  "module.transformer.decoder.layers.2.linear1.bias": 2048,
  "module.transformer.decoder.layers.2.linear2.weight": 524288,
  "module.transformer.decoder.layers.2.linear2.bias": 256,
  "module.transformer.decoder.layers.2.norm3.weight": 256,
  "module.transformer.decoder.layers.2.norm3.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.3.norm1.weight": 256,
  "module.transformer.decoder.layers.3.norm1.bias": 256,
  "module.transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.3.catext_norm.weight": 256,
  "module.transformer.decoder.layers.3.catext_norm.bias": 256,
  "module.transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.3.norm2.weight": 256,
  "module.transformer.decoder.layers.3.norm2.bias": 256,
  "module.transformer.decoder.layers.3.linear1.weight": 524288,
  "module.transformer.decoder.layers.3.linear1.bias": 2048,
  "module.transformer.decoder.layers.3.linear2.weight": 524288,
  "module.transformer.decoder.layers.3.linear2.bias": 256,
  "module.transformer.decoder.layers.3.norm3.weight": 256,
  "module.transformer.decoder.layers.3.norm3.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.4.norm1.weight": 256,
  "module.transformer.decoder.layers.4.norm1.bias": 256,
  "module.transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.4.catext_norm.weight": 256,
  "module.transformer.decoder.layers.4.catext_norm.bias": 256,
  "module.transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.4.norm2.weight": 256,
  "module.transformer.decoder.layers.4.norm2.bias": 256,
  "module.transformer.decoder.layers.4.linear1.weight": 524288,
  "module.transformer.decoder.layers.4.linear1.bias": 2048,
  "module.transformer.decoder.layers.4.linear2.weight": 524288,
  "module.transformer.decoder.layers.4.linear2.bias": 256,
  "module.transformer.decoder.layers.4.norm3.weight": 256,
  "module.transformer.decoder.layers.4.norm3.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.5.norm1.weight": 256,
  "module.transformer.decoder.layers.5.norm1.bias": 256,
  "module.transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.5.catext_norm.weight": 256,
  "module.transformer.decoder.layers.5.catext_norm.bias": 256,
  "module.transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.5.norm2.weight": 256,
  "module.transformer.decoder.layers.5.norm2.bias": 256,
  "module.transformer.decoder.layers.5.linear1.weight": 524288,
  "module.transformer.decoder.layers.5.linear1.bias": 2048,
  "module.transformer.decoder.layers.5.linear2.weight": 524288,
  "module.transformer.decoder.layers.5.linear2.bias": 256,
  "module.transformer.decoder.layers.5.norm3.weight": 256,
  "module.transformer.decoder.layers.5.norm3.bias": 256,
  "module.transformer.decoder.norm.weight": 256,
  "module.transformer.decoder.norm.bias": 256,
  "module.transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "module.transformer.decoder.ref_point_head.layers.0.bias": 256,
  "module.transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "module.transformer.decoder.ref_point_head.layers.1.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "module.transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "module.transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "module.transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "module.transformer.tgt_embed.weight": 230400,
  "module.transformer.enc_output.weight": 65536,
  "module.transformer.enc_output.bias": 256,
  "module.transformer.enc_output_norm.weight": 256,
  "module.transformer.enc_output_norm.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "module.transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "module.transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "module.transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "module.bert.embeddings.word_embeddings.weight": 23440896,
  "module.bert.embeddings.position_embeddings.weight": 393216,
  "module.bert.embeddings.token_type_embeddings.weight": 1536,
  "module.bert.embeddings.LayerNorm.weight": 768,
  "module.bert.embeddings.LayerNorm.bias": 768,
  "module.bert.encoder.layer.0.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.0.attention.self.query.bias": 768,
  "module.bert.encoder.layer.0.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.0.attention.self.key.bias": 768,
  "module.bert.encoder.layer.0.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.0.attention.self.value.bias": 768,
  "module.bert.encoder.layer.0.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.0.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.0.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.0.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.0.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.0.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.0.output.dense.weight": 2359296,
  "module.bert.encoder.layer.0.output.dense.bias": 768,
  "module.bert.encoder.layer.0.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.0.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.1.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.1.attention.self.query.bias": 768,
  "module.bert.encoder.layer.1.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.1.attention.self.key.bias": 768,
  "module.bert.encoder.layer.1.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.1.attention.self.value.bias": 768,
  "module.bert.encoder.layer.1.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.1.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.1.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.1.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.1.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.1.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.1.output.dense.weight": 2359296,
  "module.bert.encoder.layer.1.output.dense.bias": 768,
  "module.bert.encoder.layer.1.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.1.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.2.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.2.attention.self.query.bias": 768,
  "module.bert.encoder.layer.2.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.2.attention.self.key.bias": 768,
  "module.bert.encoder.layer.2.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.2.attention.self.value.bias": 768,
  "module.bert.encoder.layer.2.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.2.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.2.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.2.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.2.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.2.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.2.output.dense.weight": 2359296,
  "module.bert.encoder.layer.2.output.dense.bias": 768,
  "module.bert.encoder.layer.2.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.2.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.3.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.3.attention.self.query.bias": 768,
  "module.bert.encoder.layer.3.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.3.attention.self.key.bias": 768,
  "module.bert.encoder.layer.3.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.3.attention.self.value.bias": 768,
  "module.bert.encoder.layer.3.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.3.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.3.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.3.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.3.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.3.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.3.output.dense.weight": 2359296,
  "module.bert.encoder.layer.3.output.dense.bias": 768,
  "module.bert.encoder.layer.3.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.3.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.4.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.4.attention.self.query.bias": 768,
  "module.bert.encoder.layer.4.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.4.attention.self.key.bias": 768,
  "module.bert.encoder.layer.4.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.4.attention.self.value.bias": 768,
  "module.bert.encoder.layer.4.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.4.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.4.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.4.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.4.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.4.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.4.output.dense.weight": 2359296,
  "module.bert.encoder.layer.4.output.dense.bias": 768,
  "module.bert.encoder.layer.4.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.4.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.5.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.5.attention.self.query.bias": 768,
  "module.bert.encoder.layer.5.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.5.attention.self.key.bias": 768,
  "module.bert.encoder.layer.5.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.5.attention.self.value.bias": 768,
  "module.bert.encoder.layer.5.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.5.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.5.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.5.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.5.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.5.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.5.output.dense.weight": 2359296,
  "module.bert.encoder.layer.5.output.dense.bias": 768,
  "module.bert.encoder.layer.5.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.5.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.6.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.6.attention.self.query.bias": 768,
  "module.bert.encoder.layer.6.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.6.attention.self.key.bias": 768,
  "module.bert.encoder.layer.6.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.6.attention.self.value.bias": 768,
  "module.bert.encoder.layer.6.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.6.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.6.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.6.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.6.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.6.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.6.output.dense.weight": 2359296,
  "module.bert.encoder.layer.6.output.dense.bias": 768,
  "module.bert.encoder.layer.6.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.6.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.7.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.7.attention.self.query.bias": 768,
  "module.bert.encoder.layer.7.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.7.attention.self.key.bias": 768,
  "module.bert.encoder.layer.7.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.7.attention.self.value.bias": 768,
  "module.bert.encoder.layer.7.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.7.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.7.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.7.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.7.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.7.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.7.output.dense.weight": 2359296,
  "module.bert.encoder.layer.7.output.dense.bias": 768,
  "module.bert.encoder.layer.7.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.7.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.8.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.8.attention.self.query.bias": 768,
  "module.bert.encoder.layer.8.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.8.attention.self.key.bias": 768,
  "module.bert.encoder.layer.8.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.8.attention.self.value.bias": 768,
  "module.bert.encoder.layer.8.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.8.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.8.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.8.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.8.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.8.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.8.output.dense.weight": 2359296,
  "module.bert.encoder.layer.8.output.dense.bias": 768,
  "module.bert.encoder.layer.8.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.8.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.9.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.9.attention.self.query.bias": 768,
  "module.bert.encoder.layer.9.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.9.attention.self.key.bias": 768,
  "module.bert.encoder.layer.9.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.9.attention.self.value.bias": 768,
  "module.bert.encoder.layer.9.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.9.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.9.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.9.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.9.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.9.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.9.output.dense.weight": 2359296,
  "module.bert.encoder.layer.9.output.dense.bias": 768,
  "module.bert.encoder.layer.9.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.9.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.10.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.10.attention.self.query.bias": 768,
  "module.bert.encoder.layer.10.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.10.attention.self.key.bias": 768,
  "module.bert.encoder.layer.10.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.10.attention.self.value.bias": 768,
  "module.bert.encoder.layer.10.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.10.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.10.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.10.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.10.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.10.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.10.output.dense.weight": 2359296,
  "module.bert.encoder.layer.10.output.dense.bias": 768,
  "module.bert.encoder.layer.10.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.10.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.11.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.11.attention.self.query.bias": 768,
  "module.bert.encoder.layer.11.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.11.attention.self.key.bias": 768,
  "module.bert.encoder.layer.11.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.11.attention.self.value.bias": 768,
  "module.bert.encoder.layer.11.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.11.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.11.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.11.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.11.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.11.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.11.output.dense.weight": 2359296,
  "module.bert.encoder.layer.11.output.dense.bias": 768,
  "module.bert.encoder.layer.11.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.11.output.LayerNorm.bias": 768,
  "module.feat_map.weight": 196608,
  "module.feat_map.bias": 256,
  "module.input_proj.0.0.weight": 65536,
  "module.input_proj.0.0.bias": 256,
  "module.input_proj.0.1.weight": 256,
  "module.input_proj.0.1.bias": 256,
  "module.input_proj.1.0.weight": 131072,
  "module.input_proj.1.0.bias": 256,
  "module.input_proj.1.1.weight": 256,
  "module.input_proj.1.1.bias": 256,
  "module.input_proj.2.0.weight": 262144,
  "module.input_proj.2.0.bias": 256,
  "module.input_proj.2.1.weight": 256,
  "module.input_proj.2.1.bias": 256,
  "module.input_proj.3.0.weight": 2359296,
  "module.input_proj.3.0.bias": 256,
  "module.input_proj.3.1.weight": 256,
  "module.input_proj.3.1.bias": 256,
  "module.backbone.0.patch_embed.proj.weight": 6144,
  "module.backbone.0.patch_embed.proj.bias": 128,
  "module.backbone.0.patch_embed.norm.weight": 128,
  "module.backbone.0.patch_embed.norm.bias": 128,
  "module.backbone.0.layers.0.blocks.0.norm1.weight": 128,
  "module.backbone.0.layers.0.blocks.0.norm1.bias": 128,
  "module.backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 2116,
  "module.backbone.0.layers.0.blocks.0.attn.qkv.weight": 49152,
  "module.backbone.0.layers.0.blocks.0.attn.qkv.bias": 384,
  "module.backbone.0.layers.0.blocks.0.attn.proj.weight": 16384,
  "module.backbone.0.layers.0.blocks.0.attn.proj.bias": 128,
  "module.backbone.0.layers.0.blocks.0.norm2.weight": 128,
  "module.backbone.0.layers.0.blocks.0.norm2.bias": 128,
  "module.backbone.0.layers.0.blocks.0.mlp.fc1.weight": 65536,
  "module.backbone.0.layers.0.blocks.0.mlp.fc1.bias": 512,
  "module.backbone.0.layers.0.blocks.0.mlp.fc2.weight": 65536,
  "module.backbone.0.layers.0.blocks.0.mlp.fc2.bias": 128,
  "module.backbone.0.layers.0.blocks.1.norm1.weight": 128,
  "module.backbone.0.layers.0.blocks.1.norm1.bias": 128,
  "module.backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 2116,
  "module.backbone.0.layers.0.blocks.1.attn.qkv.weight": 49152,
  "module.backbone.0.layers.0.blocks.1.attn.qkv.bias": 384,
  "module.backbone.0.layers.0.blocks.1.attn.proj.weight": 16384,
  "module.backbone.0.layers.0.blocks.1.attn.proj.bias": 128,
  "module.backbone.0.layers.0.blocks.1.norm2.weight": 128,
  "module.backbone.0.layers.0.blocks.1.norm2.bias": 128,
  "module.backbone.0.layers.0.blocks.1.mlp.fc1.weight": 65536,
  "module.backbone.0.layers.0.blocks.1.mlp.fc1.bias": 512,
  "module.backbone.0.layers.0.blocks.1.mlp.fc2.weight": 65536,
  "module.backbone.0.layers.0.blocks.1.mlp.fc2.bias": 128,
  "module.backbone.0.layers.0.downsample.reduction.weight": 131072,
  "module.backbone.0.layers.0.downsample.norm.weight": 512,
  "module.backbone.0.layers.0.downsample.norm.bias": 512,
  "module.backbone.0.layers.1.blocks.0.norm1.weight": 256,
  "module.backbone.0.layers.1.blocks.0.norm1.bias": 256,
  "module.backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 4232,
  "module.backbone.0.layers.1.blocks.0.attn.qkv.weight": 196608,
  "module.backbone.0.layers.1.blocks.0.attn.qkv.bias": 768,
  "module.backbone.0.layers.1.blocks.0.attn.proj.weight": 65536,
  "module.backbone.0.layers.1.blocks.0.attn.proj.bias": 256,
  "module.backbone.0.layers.1.blocks.0.norm2.weight": 256,
  "module.backbone.0.layers.1.blocks.0.norm2.bias": 256,
  "module.backbone.0.layers.1.blocks.0.mlp.fc1.weight": 262144,
  "module.backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1024,
  "module.backbone.0.layers.1.blocks.0.mlp.fc2.weight": 262144,
  "module.backbone.0.layers.1.blocks.0.mlp.fc2.bias": 256,
  "module.backbone.0.layers.1.blocks.1.norm1.weight": 256,
  "module.backbone.0.layers.1.blocks.1.norm1.bias": 256,
  "module.backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 4232,
  "module.backbone.0.layers.1.blocks.1.attn.qkv.weight": 196608,
  "module.backbone.0.layers.1.blocks.1.attn.qkv.bias": 768,
  "module.backbone.0.layers.1.blocks.1.attn.proj.weight": 65536,
  "module.backbone.0.layers.1.blocks.1.attn.proj.bias": 256,
  "module.backbone.0.layers.1.blocks.1.norm2.weight": 256,
  "module.backbone.0.layers.1.blocks.1.norm2.bias": 256,
  "module.backbone.0.layers.1.blocks.1.mlp.fc1.weight": 262144,
  "module.backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1024,
  "module.backbone.0.layers.1.blocks.1.mlp.fc2.weight": 262144,
  "module.backbone.0.layers.1.blocks.1.mlp.fc2.bias": 256,
  "module.backbone.0.layers.1.downsample.reduction.weight": 524288,
  "module.backbone.0.layers.1.downsample.norm.weight": 1024,
  "module.backbone.0.layers.1.downsample.norm.bias": 1024,
  "module.backbone.0.layers.2.blocks.0.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.0.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.0.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.0.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.0.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.0.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.0.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.0.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.0.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.0.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.0.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.0.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.1.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.1.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.1.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.1.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.1.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.1.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.1.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.1.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.1.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.1.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.1.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.1.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.2.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.2.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.2.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.2.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.2.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.2.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.2.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.2.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.2.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.2.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.2.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.2.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.3.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.3.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.3.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.3.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.3.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.3.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.3.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.3.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.3.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.3.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.3.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.3.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.4.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.4.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.4.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.4.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.4.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.4.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.4.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.4.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.4.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.4.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.4.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.4.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.5.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.5.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.5.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.5.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.5.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.5.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.5.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.5.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.5.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.5.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.5.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.5.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.6.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.6.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.6.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.6.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.6.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.6.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.6.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.6.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.6.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.6.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.6.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.6.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.7.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.7.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.7.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.7.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.7.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.7.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.7.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.7.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.7.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.7.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.7.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.7.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.8.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.8.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.8.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.8.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.8.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.8.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.8.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.8.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.8.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.8.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.8.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.8.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.9.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.9.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.9.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.9.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.9.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.9.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.9.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.9.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.9.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.9.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.9.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.9.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.10.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.10.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.10.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.10.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.10.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.10.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.10.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.10.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.10.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.10.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.10.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.10.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.11.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.11.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.11.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.11.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.11.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.11.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.11.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.11.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.11.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.11.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.11.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.11.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.12.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.12.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.12.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.12.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.12.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.12.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.12.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.12.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.12.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.12.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.12.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.12.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.13.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.13.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.13.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.13.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.13.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.13.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.13.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.13.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.13.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.13.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.13.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.13.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.14.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.14.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.14.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.14.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.14.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.14.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.14.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.14.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.14.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.14.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.14.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.14.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.15.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.15.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.15.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.15.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.15.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.15.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.15.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.15.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.15.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.15.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.15.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.15.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.16.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.16.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.16.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.16.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.16.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.16.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.16.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.16.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.16.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.16.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.16.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.16.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.17.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.17.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.17.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.17.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.17.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.17.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.17.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.17.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.17.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.17.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.17.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.17.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.downsample.reduction.weight": 2097152,
  "module.backbone.0.layers.2.downsample.norm.weight": 2048,
  "module.backbone.0.layers.2.downsample.norm.bias": 2048,
  "module.backbone.0.layers.3.blocks.0.norm1.weight": 1024,
  "module.backbone.0.layers.3.blocks.0.norm1.bias": 1024,
  "module.backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 16928,
  "module.backbone.0.layers.3.blocks.0.attn.qkv.weight": 3145728,
  "module.backbone.0.layers.3.blocks.0.attn.qkv.bias": 3072,
  "module.backbone.0.layers.3.blocks.0.attn.proj.weight": 1048576,
  "module.backbone.0.layers.3.blocks.0.attn.proj.bias": 1024,
  "module.backbone.0.layers.3.blocks.0.norm2.weight": 1024,
  "module.backbone.0.layers.3.blocks.0.norm2.bias": 1024,
  "module.backbone.0.layers.3.blocks.0.mlp.fc1.weight": 4194304,
  "module.backbone.0.layers.3.blocks.0.mlp.fc1.bias": 4096,
  "module.backbone.0.layers.3.blocks.0.mlp.fc2.weight": 4194304,
  "module.backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1024,
  "module.backbone.0.layers.3.blocks.1.norm1.weight": 1024,
  "module.backbone.0.layers.3.blocks.1.norm1.bias": 1024,
  "module.backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 16928,
  "module.backbone.0.layers.3.blocks.1.attn.qkv.weight": 3145728,
  "module.backbone.0.layers.3.blocks.1.attn.qkv.bias": 3072,
  "module.backbone.0.layers.3.blocks.1.attn.proj.weight": 1048576,
  "module.backbone.0.layers.3.blocks.1.attn.proj.bias": 1024,
  "module.backbone.0.layers.3.blocks.1.norm2.weight": 1024,
  "module.backbone.0.layers.3.blocks.1.norm2.bias": 1024,
  "module.backbone.0.layers.3.blocks.1.mlp.fc1.weight": 4194304,
  "module.backbone.0.layers.3.blocks.1.mlp.fc1.bias": 4096,
  "module.backbone.0.layers.3.blocks.1.mlp.fc2.weight": 4194304,
  "module.backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1024,
  "module.backbone.0.norm1.weight": 256,
  "module.backbone.0.norm1.bias": 256,
  "module.backbone.0.norm2.weight": 512,
  "module.backbone.0.norm2.bias": 512,
  "module.backbone.0.norm3.weight": 1024,
  "module.backbone.0.norm3.bias": 1024
}[0m
[32mINFO    [0m [32m2025-10-24 02:05:32,055 | [34mparams after freezing:
{
  "module.transformer.level_embed": 1024,
  "module.transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.0.norm1.weight": 256,
  "module.transformer.encoder.layers.0.norm1.bias": 256,
  "module.transformer.encoder.layers.0.linear1.weight": 524288,
  "module.transformer.encoder.layers.0.linear1.bias": 2048,
  "module.transformer.encoder.layers.0.linear2.weight": 524288,
  "module.transformer.encoder.layers.0.linear2.bias": 256,
  "module.transformer.encoder.layers.0.norm2.weight": 256,
  "module.transformer.encoder.layers.0.norm2.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.1.norm1.weight": 256,
  "module.transformer.encoder.layers.1.norm1.bias": 256,
  "module.transformer.encoder.layers.1.linear1.weight": 524288,
  "module.transformer.encoder.layers.1.linear1.bias": 2048,
  "module.transformer.encoder.layers.1.linear2.weight": 524288,
  "module.transformer.encoder.layers.1.linear2.bias": 256,
  "module.transformer.encoder.layers.1.norm2.weight": 256,
  "module.transformer.encoder.layers.1.norm2.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.2.norm1.weight": 256,
  "module.transformer.encoder.layers.2.norm1.bias": 256,
  "module.transformer.encoder.layers.2.linear1.weight": 524288,
  "module.transformer.encoder.layers.2.linear1.bias": 2048,
  "module.transformer.encoder.layers.2.linear2.weight": 524288,
  "module.transformer.encoder.layers.2.linear2.bias": 256,
  "module.transformer.encoder.layers.2.norm2.weight": 256,
  "module.transformer.encoder.layers.2.norm2.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.3.norm1.weight": 256,
  "module.transformer.encoder.layers.3.norm1.bias": 256,
  "module.transformer.encoder.layers.3.linear1.weight": 524288,
  "module.transformer.encoder.layers.3.linear1.bias": 2048,
  "module.transformer.encoder.layers.3.linear2.weight": 524288,
  "module.transformer.encoder.layers.3.linear2.bias": 256,
  "module.transformer.encoder.layers.3.norm2.weight": 256,
  "module.transformer.encoder.layers.3.norm2.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.4.norm1.weight": 256,
  "module.transformer.encoder.layers.4.norm1.bias": 256,
  "module.transformer.encoder.layers.4.linear1.weight": 524288,
  "module.transformer.encoder.layers.4.linear1.bias": 2048,
  "module.transformer.encoder.layers.4.linear2.weight": 524288,
  "module.transformer.encoder.layers.4.linear2.bias": 256,
  "module.transformer.encoder.layers.4.norm2.weight": 256,
  "module.transformer.encoder.layers.4.norm2.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.5.norm1.weight": 256,
  "module.transformer.encoder.layers.5.norm1.bias": 256,
  "module.transformer.encoder.layers.5.linear1.weight": 524288,
  "module.transformer.encoder.layers.5.linear1.bias": 2048,
  "module.transformer.encoder.layers.5.linear2.weight": 524288,
  "module.transformer.encoder.layers.5.linear2.bias": 256,
  "module.transformer.encoder.layers.5.norm2.weight": 256,
  "module.transformer.encoder.layers.5.norm2.bias": 256,
  "module.transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.0.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.0.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.0.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.0.linear2.bias": 256,
  "module.transformer.encoder.text_layers.0.norm1.weight": 256,
  "module.transformer.encoder.text_layers.0.norm1.bias": 256,
  "module.transformer.encoder.text_layers.0.norm2.weight": 256,
  "module.transformer.encoder.text_layers.0.norm2.bias": 256,
  "module.transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.1.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.1.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.1.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.1.linear2.bias": 256,
  "module.transformer.encoder.text_layers.1.norm1.weight": 256,
  "module.transformer.encoder.text_layers.1.norm1.bias": 256,
  "module.transformer.encoder.text_layers.1.norm2.weight": 256,
  "module.transformer.encoder.text_layers.1.norm2.bias": 256,
  "module.transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.2.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.2.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.2.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.2.linear2.bias": 256,
  "module.transformer.encoder.text_layers.2.norm1.weight": 256,
  "module.transformer.encoder.text_layers.2.norm1.bias": 256,
  "module.transformer.encoder.text_layers.2.norm2.weight": 256,
  "module.transformer.encoder.text_layers.2.norm2.bias": 256,
  "module.transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.3.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.3.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.3.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.3.linear2.bias": 256,
  "module.transformer.encoder.text_layers.3.norm1.weight": 256,
  "module.transformer.encoder.text_layers.3.norm1.bias": 256,
  "module.transformer.encoder.text_layers.3.norm2.weight": 256,
  "module.transformer.encoder.text_layers.3.norm2.bias": 256,
  "module.transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.4.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.4.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.4.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.4.linear2.bias": 256,
  "module.transformer.encoder.text_layers.4.norm1.weight": 256,
  "module.transformer.encoder.text_layers.4.norm1.bias": 256,
  "module.transformer.encoder.text_layers.4.norm2.weight": 256,
  "module.transformer.encoder.text_layers.4.norm2.bias": 256,
  "module.transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.5.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.5.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.5.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.5.linear2.bias": 256,
  "module.transformer.encoder.text_layers.5.norm1.weight": 256,
  "module.transformer.encoder.text_layers.5.norm1.bias": 256,
  "module.transformer.encoder.text_layers.5.norm2.weight": 256,
  "module.transformer.encoder.text_layers.5.norm2.bias": 256,
  "module.transformer.encoder.fusion_layers.0.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.0.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.1.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.1.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.2.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.2.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.3.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.3.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.4.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.4.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.5.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.5.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.0.norm1.weight": 256,
  "module.transformer.decoder.layers.0.norm1.bias": 256,
  "module.transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.0.catext_norm.weight": 256,
  "module.transformer.decoder.layers.0.catext_norm.bias": 256,
  "module.transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.0.norm2.weight": 256,
  "module.transformer.decoder.layers.0.norm2.bias": 256,
  "module.transformer.decoder.layers.0.linear1.weight": 524288,
  "module.transformer.decoder.layers.0.linear1.bias": 2048,
  "module.transformer.decoder.layers.0.linear2.weight": 524288,
  "module.transformer.decoder.layers.0.linear2.bias": 256,
  "module.transformer.decoder.layers.0.norm3.weight": 256,
  "module.transformer.decoder.layers.0.norm3.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.1.norm1.weight": 256,
  "module.transformer.decoder.layers.1.norm1.bias": 256,
  "module.transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.1.catext_norm.weight": 256,
  "module.transformer.decoder.layers.1.catext_norm.bias": 256,
  "module.transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.1.norm2.weight": 256,
  "module.transformer.decoder.layers.1.norm2.bias": 256,
  "module.transformer.decoder.layers.1.linear1.weight": 524288,
  "module.transformer.decoder.layers.1.linear1.bias": 2048,
  "module.transformer.decoder.layers.1.linear2.weight": 524288,
  "module.transformer.decoder.layers.1.linear2.bias": 256,
  "module.transformer.decoder.layers.1.norm3.weight": 256,
  "module.transformer.decoder.layers.1.norm3.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.2.norm1.weight": 256,
  "module.transformer.decoder.layers.2.norm1.bias": 256,
  "module.transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.2.catext_norm.weight": 256,
  "module.transformer.decoder.layers.2.catext_norm.bias": 256,
  "module.transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.2.norm2.weight": 256,
  "module.transformer.decoder.layers.2.norm2.bias": 256,
  "module.transformer.decoder.layers.2.linear1.weight": 524288,
  "module.transformer.decoder.layers.2.linear1.bias": 2048,
  "module.transformer.decoder.layers.2.linear2.weight": 524288,
  "module.transformer.decoder.layers.2.linear2.bias": 256,
  "module.transformer.decoder.layers.2.norm3.weight": 256,
  "module.transformer.decoder.layers.2.norm3.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.3.norm1.weight": 256,
  "module.transformer.decoder.layers.3.norm1.bias": 256,
  "module.transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.3.catext_norm.weight": 256,
  "module.transformer.decoder.layers.3.catext_norm.bias": 256,
  "module.transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.3.norm2.weight": 256,
  "module.transformer.decoder.layers.3.norm2.bias": 256,
  "module.transformer.decoder.layers.3.linear1.weight": 524288,
  "module.transformer.decoder.layers.3.linear1.bias": 2048,
  "module.transformer.decoder.layers.3.linear2.weight": 524288,
  "module.transformer.decoder.layers.3.linear2.bias": 256,
  "module.transformer.decoder.layers.3.norm3.weight": 256,
  "module.transformer.decoder.layers.3.norm3.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.4.norm1.weight": 256,
  "module.transformer.decoder.layers.4.norm1.bias": 256,
  "module.transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.4.catext_norm.weight": 256,
  "module.transformer.decoder.layers.4.catext_norm.bias": 256,
  "module.transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.4.norm2.weight": 256,
  "module.transformer.decoder.layers.4.norm2.bias": 256,
  "module.transformer.decoder.layers.4.linear1.weight": 524288,
  "module.transformer.decoder.layers.4.linear1.bias": 2048,
  "module.transformer.decoder.layers.4.linear2.weight": 524288,
  "module.transformer.decoder.layers.4.linear2.bias": 256,
  "module.transformer.decoder.layers.4.norm3.weight": 256,
  "module.transformer.decoder.layers.4.norm3.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.5.norm1.weight": 256,
  "module.transformer.decoder.layers.5.norm1.bias": 256,
  "module.transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.5.catext_norm.weight": 256,
  "module.transformer.decoder.layers.5.catext_norm.bias": 256,
  "module.transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.5.norm2.weight": 256,
  "module.transformer.decoder.layers.5.norm2.bias": 256,
  "module.transformer.decoder.layers.5.linear1.weight": 524288,
  "module.transformer.decoder.layers.5.linear1.bias": 2048,
  "module.transformer.decoder.layers.5.linear2.weight": 524288,
  "module.transformer.decoder.layers.5.linear2.bias": 256,
  "module.transformer.decoder.layers.5.norm3.weight": 256,
  "module.transformer.decoder.layers.5.norm3.bias": 256,
  "module.transformer.decoder.norm.weight": 256,
  "module.transformer.decoder.norm.bias": 256,
  "module.transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "module.transformer.decoder.ref_point_head.layers.0.bias": 256,
  "module.transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "module.transformer.decoder.ref_point_head.layers.1.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "module.transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "module.transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "module.transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "module.transformer.tgt_embed.weight": 230400,
  "module.transformer.enc_output.weight": 65536,
  "module.transformer.enc_output.bias": 256,
  "module.transformer.enc_output_norm.weight": 256,
  "module.transformer.enc_output_norm.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "module.transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "module.transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "module.transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "module.feat_map.weight": 196608,
  "module.feat_map.bias": 256,
  "module.input_proj.0.0.weight": 65536,
  "module.input_proj.0.0.bias": 256,
  "module.input_proj.0.1.weight": 256,
  "module.input_proj.0.1.bias": 256,
  "module.input_proj.1.0.weight": 131072,
  "module.input_proj.1.0.bias": 256,
  "module.input_proj.1.1.weight": 256,
  "module.input_proj.1.1.bias": 256,
  "module.input_proj.2.0.weight": 262144,
  "module.input_proj.2.0.bias": 256,
  "module.input_proj.2.1.weight": 256,
  "module.input_proj.2.1.bias": 256,
  "module.input_proj.3.0.weight": 2359296,
  "module.input_proj.3.0.bias": 256,
  "module.input_proj.3.1.weight": 256,
  "module.input_proj.3.1.bias": 256,
  "module.backbone.0.patch_embed.proj.weight": 6144,
  "module.backbone.0.patch_embed.proj.bias": 128,
  "module.backbone.0.patch_embed.norm.weight": 128,
  "module.backbone.0.patch_embed.norm.bias": 128,
  "module.backbone.0.layers.0.blocks.0.norm1.weight": 128,
  "module.backbone.0.layers.0.blocks.0.norm1.bias": 128,
  "module.backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 2116,
  "module.backbone.0.layers.0.blocks.0.attn.qkv.weight": 49152,
  "module.backbone.0.layers.0.blocks.0.attn.qkv.bias": 384,
  "module.backbone.0.layers.0.blocks.0.attn.proj.weight": 16384,
  "module.backbone.0.layers.0.blocks.0.attn.proj.bias": 128,
  "module.backbone.0.layers.0.blocks.0.norm2.weight": 128,
  "module.backbone.0.layers.0.blocks.0.norm2.bias": 128,
  "module.backbone.0.layers.0.blocks.0.mlp.fc1.weight": 65536,
  "module.backbone.0.layers.0.blocks.0.mlp.fc1.bias": 512,
  "module.backbone.0.layers.0.blocks.0.mlp.fc2.weight": 65536,
  "module.backbone.0.layers.0.blocks.0.mlp.fc2.bias": 128,
  "module.backbone.0.layers.0.blocks.1.norm1.weight": 128,
  "module.backbone.0.layers.0.blocks.1.norm1.bias": 128,
  "module.backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 2116,
  "module.backbone.0.layers.0.blocks.1.attn.qkv.weight": 49152,
  "module.backbone.0.layers.0.blocks.1.attn.qkv.bias": 384,
  "module.backbone.0.layers.0.blocks.1.attn.proj.weight": 16384,
  "module.backbone.0.layers.0.blocks.1.attn.proj.bias": 128,
  "module.backbone.0.layers.0.blocks.1.norm2.weight": 128,
  "module.backbone.0.layers.0.blocks.1.norm2.bias": 128,
  "module.backbone.0.layers.0.blocks.1.mlp.fc1.weight": 65536,
  "module.backbone.0.layers.0.blocks.1.mlp.fc1.bias": 512,
  "module.backbone.0.layers.0.blocks.1.mlp.fc2.weight": 65536,
  "module.backbone.0.layers.0.blocks.1.mlp.fc2.bias": 128,
  "module.backbone.0.layers.0.downsample.reduction.weight": 131072,
  "module.backbone.0.layers.0.downsample.norm.weight": 512,
  "module.backbone.0.layers.0.downsample.norm.bias": 512,
  "module.backbone.0.layers.1.blocks.0.norm1.weight": 256,
  "module.backbone.0.layers.1.blocks.0.norm1.bias": 256,
  "module.backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 4232,
  "module.backbone.0.layers.1.blocks.0.attn.qkv.weight": 196608,
  "module.backbone.0.layers.1.blocks.0.attn.qkv.bias": 768,
  "module.backbone.0.layers.1.blocks.0.attn.proj.weight": 65536,
  "module.backbone.0.layers.1.blocks.0.attn.proj.bias": 256,
  "module.backbone.0.layers.1.blocks.0.norm2.weight": 256,
  "module.backbone.0.layers.1.blocks.0.norm2.bias": 256,
  "module.backbone.0.layers.1.blocks.0.mlp.fc1.weight": 262144,
  "module.backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1024,
  "module.backbone.0.layers.1.blocks.0.mlp.fc2.weight": 262144,
  "module.backbone.0.layers.1.blocks.0.mlp.fc2.bias": 256,
  "module.backbone.0.layers.1.blocks.1.norm1.weight": 256,
  "module.backbone.0.layers.1.blocks.1.norm1.bias": 256,
  "module.backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 4232,
  "module.backbone.0.layers.1.blocks.1.attn.qkv.weight": 196608,
  "module.backbone.0.layers.1.blocks.1.attn.qkv.bias": 768,
  "module.backbone.0.layers.1.blocks.1.attn.proj.weight": 65536,
  "module.backbone.0.layers.1.blocks.1.attn.proj.bias": 256,
  "module.backbone.0.layers.1.blocks.1.norm2.weight": 256,
  "module.backbone.0.layers.1.blocks.1.norm2.bias": 256,
  "module.backbone.0.layers.1.blocks.1.mlp.fc1.weight": 262144,
  "module.backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1024,
  "module.backbone.0.layers.1.blocks.1.mlp.fc2.weight": 262144,
  "module.backbone.0.layers.1.blocks.1.mlp.fc2.bias": 256,
  "module.backbone.0.layers.1.downsample.reduction.weight": 524288,
  "module.backbone.0.layers.1.downsample.norm.weight": 1024,
  "module.backbone.0.layers.1.downsample.norm.bias": 1024,
  "module.backbone.0.layers.2.blocks.0.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.0.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.0.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.0.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.0.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.0.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.0.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.0.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.0.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.0.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.0.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.0.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.1.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.1.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.1.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.1.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.1.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.1.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.1.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.1.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.1.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.1.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.1.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.1.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.2.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.2.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.2.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.2.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.2.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.2.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.2.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.2.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.2.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.2.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.2.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.2.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.3.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.3.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.3.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.3.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.3.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.3.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.3.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.3.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.3.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.3.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.3.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.3.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.4.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.4.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.4.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.4.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.4.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.4.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.4.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.4.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.4.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.4.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.4.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.4.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.5.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.5.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.5.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.5.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.5.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.5.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.5.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.5.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.5.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.5.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.5.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.5.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.6.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.6.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.6.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.6.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.6.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.6.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.6.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.6.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.6.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.6.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.6.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.6.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.7.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.7.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.7.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.7.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.7.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.7.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.7.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.7.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.7.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.7.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.7.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.7.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.8.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.8.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.8.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.8.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.8.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.8.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.8.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.8.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.8.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.8.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.8.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.8.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.9.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.9.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.9.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.9.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.9.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.9.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.9.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.9.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.9.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.9.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.9.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.9.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.10.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.10.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.10.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.10.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.10.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.10.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.10.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.10.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.10.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.10.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.10.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.10.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.11.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.11.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.11.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.11.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.11.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.11.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.11.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.11.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.11.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.11.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.11.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.11.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.12.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.12.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.12.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.12.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.12.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.12.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.12.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.12.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.12.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.12.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.12.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.12.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.13.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.13.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.13.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.13.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.13.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.13.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.13.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.13.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.13.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.13.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.13.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.13.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.14.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.14.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.14.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.14.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.14.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.14.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.14.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.14.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.14.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.14.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.14.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.14.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.15.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.15.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.15.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.15.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.15.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.15.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.15.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.15.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.15.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.15.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.15.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.15.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.16.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.16.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.16.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.16.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.16.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.16.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.16.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.16.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.16.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.16.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.16.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.16.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.17.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.17.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.17.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.17.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.17.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.17.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.17.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.17.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.17.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.17.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.17.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.17.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.downsample.reduction.weight": 2097152,
  "module.backbone.0.layers.2.downsample.norm.weight": 2048,
  "module.backbone.0.layers.2.downsample.norm.bias": 2048,
  "module.backbone.0.layers.3.blocks.0.norm1.weight": 1024,
  "module.backbone.0.layers.3.blocks.0.norm1.bias": 1024,
  "module.backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 16928,
  "module.backbone.0.layers.3.blocks.0.attn.qkv.weight": 3145728,
  "module.backbone.0.layers.3.blocks.0.attn.qkv.bias": 3072,
  "module.backbone.0.layers.3.blocks.0.attn.proj.weight": 1048576,
  "module.backbone.0.layers.3.blocks.0.attn.proj.bias": 1024,
  "module.backbone.0.layers.3.blocks.0.norm2.weight": 1024,
  "module.backbone.0.layers.3.blocks.0.norm2.bias": 1024,
  "module.backbone.0.layers.3.blocks.0.mlp.fc1.weight": 4194304,
  "module.backbone.0.layers.3.blocks.0.mlp.fc1.bias": 4096,
  "module.backbone.0.layers.3.blocks.0.mlp.fc2.weight": 4194304,
  "module.backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1024,
  "module.backbone.0.layers.3.blocks.1.norm1.weight": 1024,
  "module.backbone.0.layers.3.blocks.1.norm1.bias": 1024,
  "module.backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 16928,
  "module.backbone.0.layers.3.blocks.1.attn.qkv.weight": 3145728,
  "module.backbone.0.layers.3.blocks.1.attn.qkv.bias": 3072,
  "module.backbone.0.layers.3.blocks.1.attn.proj.weight": 1048576,
  "module.backbone.0.layers.3.blocks.1.attn.proj.bias": 1024,
  "module.backbone.0.layers.3.blocks.1.norm2.weight": 1024,
  "module.backbone.0.layers.3.blocks.1.norm2.bias": 1024,
  "module.backbone.0.layers.3.blocks.1.mlp.fc1.weight": 4194304,
  "module.backbone.0.layers.3.blocks.1.mlp.fc1.bias": 4096,
  "module.backbone.0.layers.3.blocks.1.mlp.fc2.weight": 4194304,
  "module.backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1024,
  "module.backbone.0.norm1.weight": 256,
  "module.backbone.0.norm1.bias": 256,
  "module.backbone.0.norm2.weight": 512,
  "module.backbone.0.norm2.bias": 512,
  "module.backbone.0.norm3.weight": 1024,
  "module.backbone.0.norm3.bias": 1024
}[0m
[36mDEBUG   [0m [36m2025-10-24 02:05:32,055 | [34mbuild dataset ... ...[0m
../vlmtest/GroundingDINO/dataset/kitti/training/image_02 ../vlmtest/GroundingDINO/dataset/kitti/training/kitti_odvg.jsonl None
  == total images: 4841
[36mDEBUG   [0m [36m2025-10-24 02:05:32,142 | [34mbuild dataset, done.[0m
[36mDEBUG   [0m [36m2025-10-24 02:05:32,142 | [34mnumber of training dataset: 1, samples: 4841[0m
../vlmtest/GroundingDINO/dataset/kitti/validation/image_02 ../vlmtest/GroundingDINO/dataset/kitti/validation/val_kitti.json
loading annotations into memory...
Done (t=0.03s)
creating index...
index created!
Start training
Epoch: [14]  [  0/302]  eta: 0:41:01  lr: 0.000000  loss: 3.5303 (3.5303)  loss_bbox: 0.0716 (0.0716)  loss_bbox_0: 0.0732 (0.0732)  loss_bbox_1: 0.0717 (0.0717)  loss_bbox_2: 0.0720 (0.0720)  loss_bbox_3: 0.0724 (0.0724)  loss_bbox_4: 0.0705 (0.0705)  loss_bbox_interm: 0.0929 (0.0929)  loss_ce: 0.1803 (0.1803)  loss_ce_0: 0.1747 (0.1747)  loss_ce_1: 0.1863 (0.1863)  loss_ce_2: 0.1793 (0.1793)  loss_ce_3: 0.1695 (0.1695)  loss_ce_4: 0.1762 (0.1762)  loss_ce_interm: 0.1532 (0.1532)  loss_giou: 0.2509 (0.2509)  loss_giou_0: 0.2643 (0.2643)  loss_giou_1: 0.2482 (0.2482)  loss_giou_2: 0.2497 (0.2497)  loss_giou_3: 0.2413 (0.2413)  loss_giou_4: 0.2448 (0.2448)  loss_giou_interm: 0.2872 (0.2872)  loss_bbox_unscaled: 0.0143 (0.0143)  loss_bbox_0_unscaled: 0.0146 (0.0146)  loss_bbox_1_unscaled: 0.0143 (0.0143)  loss_bbox_2_unscaled: 0.0144 (0.0144)  loss_bbox_3_unscaled: 0.0145 (0.0145)  loss_bbox_4_unscaled: 0.0141 (0.0141)  loss_bbox_interm_unscaled: 0.0186 (0.0186)  loss_ce_unscaled: 0.0902 (0.0902)  loss_ce_0_unscaled: 0.0873 (0.0873)  loss_ce_1_unscaled: 0.0932 (0.0932)  loss_ce_2_unscaled: 0.0896 (0.0896)  loss_ce_3_unscaled: 0.0848 (0.0848)  loss_ce_4_unscaled: 0.0881 (0.0881)  loss_ce_interm_unscaled: 0.0766 (0.0766)  loss_giou_unscaled: 0.1254 (0.1254)  loss_giou_0_unscaled: 0.1322 (0.1322)  loss_giou_1_unscaled: 0.1241 (0.1241)  loss_giou_2_unscaled: 0.1249 (0.1249)  loss_giou_3_unscaled: 0.1206 (0.1206)  loss_giou_4_unscaled: 0.1224 (0.1224)  loss_giou_interm_unscaled: 0.1436 (0.1436)  loss_hw_unscaled: 0.0088 (0.0088)  loss_hw_0_unscaled: 0.0091 (0.0091)  loss_hw_1_unscaled: 0.0091 (0.0091)  loss_hw_2_unscaled: 0.0087 (0.0087)  loss_hw_3_unscaled: 0.0091 (0.0091)  loss_hw_4_unscaled: 0.0085 (0.0085)  loss_hw_interm_unscaled: 0.0119 (0.0119)  loss_xy_unscaled: 0.0055 (0.0055)  loss_xy_0_unscaled: 0.0055 (0.0055)  loss_xy_1_unscaled: 0.0052 (0.0052)  loss_xy_2_unscaled: 0.0056 (0.0056)  loss_xy_3_unscaled: 0.0054 (0.0054)  loss_xy_4_unscaled: 0.0056 (0.0056)  loss_xy_interm_unscaled: 0.0067 (0.0067)  time: 8.1494  data: 3.0596  max mem: 15364
Epoch: [14]  [ 10/302]  eta: 0:20:41  lr: 0.000000  loss: 2.8854 (2.8456)  loss_bbox: 0.0681 (0.0708)  loss_bbox_0: 0.0717 (0.0731)  loss_bbox_1: 0.0717 (0.0712)  loss_bbox_2: 0.0691 (0.0717)  loss_bbox_3: 0.0693 (0.0712)  loss_bbox_4: 0.0684 (0.0714)  loss_bbox_interm: 0.0826 (0.0783)  loss_ce: 0.1017 (0.1089)  loss_ce_0: 0.1321 (0.1218)  loss_ce_1: 0.1171 (0.1188)  loss_ce_2: 0.1056 (0.1090)  loss_ce_3: 0.1008 (0.1060)  loss_ce_4: 0.0994 (0.1063)  loss_ce_interm: 0.1476 (0.1442)  loss_giou: 0.2202 (0.2126)  loss_giou_0: 0.2222 (0.2185)  loss_giou_1: 0.2218 (0.2149)  loss_giou_2: 0.2224 (0.2156)  loss_giou_3: 0.2253 (0.2136)  loss_giou_4: 0.2222 (0.2129)  loss_giou_interm: 0.2343 (0.2349)  loss_bbox_unscaled: 0.0136 (0.0142)  loss_bbox_0_unscaled: 0.0143 (0.0146)  loss_bbox_1_unscaled: 0.0143 (0.0142)  loss_bbox_2_unscaled: 0.0138 (0.0143)  loss_bbox_3_unscaled: 0.0139 (0.0142)  loss_bbox_4_unscaled: 0.0137 (0.0143)  loss_bbox_interm_unscaled: 0.0165 (0.0157)  loss_ce_unscaled: 0.0509 (0.0545)  loss_ce_0_unscaled: 0.0660 (0.0609)  loss_ce_1_unscaled: 0.0585 (0.0594)  loss_ce_2_unscaled: 0.0528 (0.0545)  loss_ce_3_unscaled: 0.0504 (0.0530)  loss_ce_4_unscaled: 0.0497 (0.0531)  loss_ce_interm_unscaled: 0.0738 (0.0721)  loss_giou_unscaled: 0.1101 (0.1063)  loss_giou_0_unscaled: 0.1111 (0.1092)  loss_giou_1_unscaled: 0.1109 (0.1074)  loss_giou_2_unscaled: 0.1112 (0.1078)  loss_giou_3_unscaled: 0.1127 (0.1068)  loss_giou_4_unscaled: 0.1111 (0.1065)  loss_giou_interm_unscaled: 0.1171 (0.1175)  loss_hw_unscaled: 0.0082 (0.0086)  loss_hw_0_unscaled: 0.0086 (0.0090)  loss_hw_1_unscaled: 0.0087 (0.0087)  loss_hw_2_unscaled: 0.0082 (0.0087)  loss_hw_3_unscaled: 0.0082 (0.0086)  loss_hw_4_unscaled: 0.0081 (0.0087)  loss_hw_interm_unscaled: 0.0099 (0.0098)  loss_xy_unscaled: 0.0055 (0.0056)  loss_xy_0_unscaled: 0.0056 (0.0056)  loss_xy_1_unscaled: 0.0057 (0.0056)  loss_xy_2_unscaled: 0.0056 (0.0056)  loss_xy_3_unscaled: 0.0054 (0.0056)  loss_xy_4_unscaled: 0.0055 (0.0056)  loss_xy_interm_unscaled: 0.0060 (0.0059)  time: 4.2523  data: 0.3149  max mem: 21141
Epoch: [14]  [ 20/302]  eta: 0:19:15  lr: 0.000000  loss: 2.8351 (2.8155)  loss_bbox: 0.0672 (0.0700)  loss_bbox_0: 0.0715 (0.0734)  loss_bbox_1: 0.0701 (0.0709)  loss_bbox_2: 0.0687 (0.0712)  loss_bbox_3: 0.0693 (0.0707)  loss_bbox_4: 0.0683 (0.0707)  loss_bbox_interm: 0.0738 (0.0771)  loss_ce: 0.0986 (0.1048)  loss_ce_0: 0.1097 (0.1147)  loss_ce_1: 0.1148 (0.1130)  loss_ce_2: 0.0957 (0.1035)  loss_ce_3: 0.1008 (0.1037)  loss_ce_4: 0.0951 (0.1024)  loss_ce_interm: 0.1409 (0.1360)  loss_giou: 0.2144 (0.2142)  loss_giou_0: 0.2222 (0.2207)  loss_giou_1: 0.2155 (0.2162)  loss_giou_2: 0.2188 (0.2176)  loss_giou_3: 0.2155 (0.2151)  loss_giou_4: 0.2173 (0.2146)  loss_giou_interm: 0.2343 (0.2352)  loss_bbox_unscaled: 0.0134 (0.0140)  loss_bbox_0_unscaled: 0.0143 (0.0147)  loss_bbox_1_unscaled: 0.0140 (0.0142)  loss_bbox_2_unscaled: 0.0137 (0.0142)  loss_bbox_3_unscaled: 0.0139 (0.0141)  loss_bbox_4_unscaled: 0.0137 (0.0141)  loss_bbox_interm_unscaled: 0.0148 (0.0154)  loss_ce_unscaled: 0.0493 (0.0524)  loss_ce_0_unscaled: 0.0549 (0.0573)  loss_ce_1_unscaled: 0.0574 (0.0565)  loss_ce_2_unscaled: 0.0478 (0.0518)  loss_ce_3_unscaled: 0.0504 (0.0518)  loss_ce_4_unscaled: 0.0476 (0.0512)  loss_ce_interm_unscaled: 0.0705 (0.0680)  loss_giou_unscaled: 0.1072 (0.1071)  loss_giou_0_unscaled: 0.1111 (0.1103)  loss_giou_1_unscaled: 0.1078 (0.1081)  loss_giou_2_unscaled: 0.1094 (0.1088)  loss_giou_3_unscaled: 0.1077 (0.1076)  loss_giou_4_unscaled: 0.1087 (0.1073)  loss_giou_interm_unscaled: 0.1171 (0.1176)  loss_hw_unscaled: 0.0081 (0.0086)  loss_hw_0_unscaled: 0.0086 (0.0091)  loss_hw_1_unscaled: 0.0085 (0.0088)  loss_hw_2_unscaled: 0.0082 (0.0088)  loss_hw_3_unscaled: 0.0082 (0.0087)  loss_hw_4_unscaled: 0.0081 (0.0087)  loss_hw_interm_unscaled: 0.0095 (0.0097)  loss_xy_unscaled: 0.0054 (0.0054)  loss_xy_0_unscaled: 0.0055 (0.0056)  loss_xy_1_unscaled: 0.0053 (0.0054)  loss_xy_2_unscaled: 0.0054 (0.0055)  loss_xy_3_unscaled: 0.0053 (0.0054)  loss_xy_4_unscaled: 0.0055 (0.0055)  loss_xy_interm_unscaled: 0.0058 (0.0058)  time: 3.8963  data: 0.0284  max mem: 21141
Epoch: [14]  [ 30/302]  eta: 0:18:33  lr: 0.000000  loss: 2.8459 (2.8239)  loss_bbox: 0.0710 (0.0710)  loss_bbox_0: 0.0719 (0.0751)  loss_bbox_1: 0.0719 (0.0725)  loss_bbox_2: 0.0738 (0.0724)  loss_bbox_3: 0.0710 (0.0719)  loss_bbox_4: 0.0718 (0.0718)  loss_bbox_interm: 0.0742 (0.0784)  loss_ce: 0.1068 (0.1050)  loss_ce_0: 0.1192 (0.1164)  loss_ce_1: 0.1185 (0.1134)  loss_ce_2: 0.1118 (0.1061)  loss_ce_3: 0.1075 (0.1056)  loss_ce_4: 0.1105 (0.1040)  loss_ce_interm: 0.1369 (0.1385)  loss_giou: 0.2144 (0.2126)  loss_giou_0: 0.2222 (0.2203)  loss_giou_1: 0.2153 (0.2149)  loss_giou_2: 0.2188 (0.2160)  loss_giou_3: 0.2155 (0.2133)  loss_giou_4: 0.2162 (0.2128)  loss_giou_interm: 0.2331 (0.2320)  loss_bbox_unscaled: 0.0142 (0.0142)  loss_bbox_0_unscaled: 0.0144 (0.0150)  loss_bbox_1_unscaled: 0.0144 (0.0145)  loss_bbox_2_unscaled: 0.0148 (0.0145)  loss_bbox_3_unscaled: 0.0142 (0.0144)  loss_bbox_4_unscaled: 0.0144 (0.0144)  loss_bbox_interm_unscaled: 0.0148 (0.0157)  loss_ce_unscaled: 0.0534 (0.0525)  loss_ce_0_unscaled: 0.0596 (0.0582)  loss_ce_1_unscaled: 0.0592 (0.0567)  loss_ce_2_unscaled: 0.0559 (0.0530)  loss_ce_3_unscaled: 0.0538 (0.0528)  loss_ce_4_unscaled: 0.0552 (0.0520)  loss_ce_interm_unscaled: 0.0684 (0.0693)  loss_giou_unscaled: 0.1072 (0.1063)  loss_giou_0_unscaled: 0.1111 (0.1102)  loss_giou_1_unscaled: 0.1077 (0.1075)  loss_giou_2_unscaled: 0.1094 (0.1080)  loss_giou_3_unscaled: 0.1077 (0.1067)  loss_giou_4_unscaled: 0.1081 (0.1064)  loss_giou_interm_unscaled: 0.1165 (0.1160)  loss_hw_unscaled: 0.0087 (0.0087)  loss_hw_0_unscaled: 0.0091 (0.0093)  loss_hw_1_unscaled: 0.0090 (0.0089)  loss_hw_2_unscaled: 0.0094 (0.0089)  loss_hw_3_unscaled: 0.0089 (0.0088)  loss_hw_4_unscaled: 0.0089 (0.0088)  loss_hw_interm_unscaled: 0.0095 (0.0098)  loss_xy_unscaled: 0.0053 (0.0055)  loss_xy_0_unscaled: 0.0055 (0.0057)  loss_xy_1_unscaled: 0.0052 (0.0056)  loss_xy_2_unscaled: 0.0053 (0.0056)  loss_xy_3_unscaled: 0.0052 (0.0055)  loss_xy_4_unscaled: 0.0053 (0.0055)  loss_xy_interm_unscaled: 0.0058 (0.0058)  time: 4.0043  data: 0.0163  max mem: 21141
Epoch: [14]  [ 40/302]  eta: 0:17:42  lr: 0.000000  loss: 2.8218 (2.8181)  loss_bbox: 0.0744 (0.0722)  loss_bbox_0: 0.0808 (0.0766)  loss_bbox_1: 0.0778 (0.0740)  loss_bbox_2: 0.0772 (0.0738)  loss_bbox_3: 0.0748 (0.0732)  loss_bbox_4: 0.0749 (0.0728)  loss_bbox_interm: 0.0804 (0.0794)  loss_ce: 0.0997 (0.1031)  loss_ce_0: 0.1055 (0.1129)  loss_ce_1: 0.1050 (0.1102)  loss_ce_2: 0.1047 (0.1037)  loss_ce_3: 0.1031 (0.1032)  loss_ce_4: 0.1039 (0.1024)  loss_ce_interm: 0.1369 (0.1357)  loss_giou: 0.2090 (0.2129)  loss_giou_0: 0.2224 (0.2218)  loss_giou_1: 0.2115 (0.2158)  loss_giou_2: 0.2129 (0.2160)  loss_giou_3: 0.2097 (0.2137)  loss_giou_4: 0.2081 (0.2130)  loss_giou_interm: 0.2233 (0.2318)  loss_bbox_unscaled: 0.0149 (0.0144)  loss_bbox_0_unscaled: 0.0162 (0.0153)  loss_bbox_1_unscaled: 0.0156 (0.0148)  loss_bbox_2_unscaled: 0.0154 (0.0148)  loss_bbox_3_unscaled: 0.0150 (0.0146)  loss_bbox_4_unscaled: 0.0150 (0.0146)  loss_bbox_interm_unscaled: 0.0161 (0.0159)  loss_ce_unscaled: 0.0498 (0.0516)  loss_ce_0_unscaled: 0.0527 (0.0564)  loss_ce_1_unscaled: 0.0525 (0.0551)  loss_ce_2_unscaled: 0.0523 (0.0519)  loss_ce_3_unscaled: 0.0516 (0.0516)  loss_ce_4_unscaled: 0.0520 (0.0512)  loss_ce_interm_unscaled: 0.0684 (0.0679)  loss_giou_unscaled: 0.1045 (0.1065)  loss_giou_0_unscaled: 0.1112 (0.1109)  loss_giou_1_unscaled: 0.1057 (0.1079)  loss_giou_2_unscaled: 0.1065 (0.1080)  loss_giou_3_unscaled: 0.1048 (0.1068)  loss_giou_4_unscaled: 0.1041 (0.1065)  loss_giou_interm_unscaled: 0.1116 (0.1159)  loss_hw_unscaled: 0.0094 (0.0089)  loss_hw_0_unscaled: 0.0097 (0.0095)  loss_hw_1_unscaled: 0.0099 (0.0092)  loss_hw_2_unscaled: 0.0097 (0.0091)  loss_hw_3_unscaled: 0.0095 (0.0090)  loss_hw_4_unscaled: 0.0094 (0.0090)  loss_hw_interm_unscaled: 0.0098 (0.0100)  loss_xy_unscaled: 0.0055 (0.0055)  loss_xy_0_unscaled: 0.0059 (0.0058)  loss_xy_1_unscaled: 0.0057 (0.0056)  loss_xy_2_unscaled: 0.0057 (0.0056)  loss_xy_3_unscaled: 0.0055 (0.0056)  loss_xy_4_unscaled: 0.0055 (0.0056)  loss_xy_interm_unscaled: 0.0060 (0.0059)  time: 4.0080  data: 0.0222  max mem: 21141
Epoch: [14]  [ 50/302]  eta: 0:16:58  lr: 0.000000  loss: 2.8012 (2.8581)  loss_bbox: 0.0762 (0.0736)  loss_bbox_0: 0.0803 (0.0779)  loss_bbox_1: 0.0778 (0.0752)  loss_bbox_2: 0.0777 (0.0751)  loss_bbox_3: 0.0763 (0.0743)  loss_bbox_4: 0.0751 (0.0738)  loss_bbox_interm: 0.0808 (0.0806)  loss_ce: 0.0864 (0.1052)  loss_ce_0: 0.1020 (0.1159)  loss_ce_1: 0.1003 (0.1133)  loss_ce_2: 0.0892 (0.1073)  loss_ce_3: 0.0907 (0.1064)  loss_ce_4: 0.0929 (0.1052)  loss_ce_interm: 0.1260 (0.1382)  loss_giou: 0.2158 (0.2143)  loss_giou_0: 0.2223 (0.2235)  loss_giou_1: 0.2173 (0.2174)  loss_giou_2: 0.2167 (0.2174)  loss_giou_3: 0.2131 (0.2153)  loss_giou_4: 0.2162 (0.2143)  loss_giou_interm: 0.2327 (0.2338)  loss_bbox_unscaled: 0.0152 (0.0147)  loss_bbox_0_unscaled: 0.0161 (0.0156)  loss_bbox_1_unscaled: 0.0156 (0.0150)  loss_bbox_2_unscaled: 0.0155 (0.0150)  loss_bbox_3_unscaled: 0.0153 (0.0149)  loss_bbox_4_unscaled: 0.0150 (0.0148)  loss_bbox_interm_unscaled: 0.0162 (0.0161)  loss_ce_unscaled: 0.0432 (0.0526)  loss_ce_0_unscaled: 0.0510 (0.0579)  loss_ce_1_unscaled: 0.0502 (0.0567)  loss_ce_2_unscaled: 0.0446 (0.0537)  loss_ce_3_unscaled: 0.0454 (0.0532)  loss_ce_4_unscaled: 0.0464 (0.0526)  loss_ce_interm_unscaled: 0.0630 (0.0691)  loss_giou_unscaled: 0.1079 (0.1072)  loss_giou_0_unscaled: 0.1111 (0.1117)  loss_giou_1_unscaled: 0.1086 (0.1087)  loss_giou_2_unscaled: 0.1084 (0.1087)  loss_giou_3_unscaled: 0.1066 (0.1076)  loss_giou_4_unscaled: 0.1081 (0.1071)  loss_giou_interm_unscaled: 0.1163 (0.1169)  loss_hw_unscaled: 0.0094 (0.0091)  loss_hw_0_unscaled: 0.0098 (0.0097)  loss_hw_1_unscaled: 0.0099 (0.0093)  loss_hw_2_unscaled: 0.0098 (0.0093)  loss_hw_3_unscaled: 0.0095 (0.0092)  loss_hw_4_unscaled: 0.0094 (0.0091)  loss_hw_interm_unscaled: 0.0102 (0.0102)  loss_xy_unscaled: 0.0055 (0.0056)  loss_xy_0_unscaled: 0.0061 (0.0058)  loss_xy_1_unscaled: 0.0057 (0.0057)  loss_xy_2_unscaled: 0.0057 (0.0057)  loss_xy_3_unscaled: 0.0057 (0.0056)  loss_xy_4_unscaled: 0.0054 (0.0056)  loss_xy_interm_unscaled: 0.0061 (0.0060)  time: 3.9665  data: 0.0226  max mem: 21141
Epoch: [14]  [ 60/302]  eta: 0:16:12  lr: 0.000000  loss: 2.7201 (2.8294)  loss_bbox: 0.0755 (0.0730)  loss_bbox_0: 0.0748 (0.0767)  loss_bbox_1: 0.0750 (0.0746)  loss_bbox_2: 0.0750 (0.0744)  loss_bbox_3: 0.0754 (0.0735)  loss_bbox_4: 0.0751 (0.0731)  loss_bbox_interm: 0.0784 (0.0795)  loss_ce: 0.0827 (0.1022)  loss_ce_0: 0.0992 (0.1146)  loss_ce_1: 0.0934 (0.1101)  loss_ce_2: 0.0812 (0.1043)  loss_ce_3: 0.0852 (0.1036)  loss_ce_4: 0.0846 (0.1020)  loss_ce_interm: 0.1169 (0.1354)  loss_giou: 0.2132 (0.2142)  loss_giou_0: 0.2192 (0.2222)  loss_giou_1: 0.2181 (0.2174)  loss_giou_2: 0.2155 (0.2172)  loss_giou_3: 0.2131 (0.2152)  loss_giou_4: 0.2125 (0.2142)  loss_giou_interm: 0.2292 (0.2321)  loss_bbox_unscaled: 0.0151 (0.0146)  loss_bbox_0_unscaled: 0.0150 (0.0153)  loss_bbox_1_unscaled: 0.0150 (0.0149)  loss_bbox_2_unscaled: 0.0150 (0.0149)  loss_bbox_3_unscaled: 0.0151 (0.0147)  loss_bbox_4_unscaled: 0.0150 (0.0146)  loss_bbox_interm_unscaled: 0.0157 (0.0159)  loss_ce_unscaled: 0.0413 (0.0511)  loss_ce_0_unscaled: 0.0496 (0.0573)  loss_ce_1_unscaled: 0.0467 (0.0550)  loss_ce_2_unscaled: 0.0406 (0.0521)  loss_ce_3_unscaled: 0.0426 (0.0518)  loss_ce_4_unscaled: 0.0423 (0.0510)  loss_ce_interm_unscaled: 0.0584 (0.0677)  loss_giou_unscaled: 0.1066 (0.1071)  loss_giou_0_unscaled: 0.1096 (0.1111)  loss_giou_1_unscaled: 0.1090 (0.1087)  loss_giou_2_unscaled: 0.1078 (0.1086)  loss_giou_3_unscaled: 0.1065 (0.1076)  loss_giou_4_unscaled: 0.1062 (0.1071)  loss_giou_interm_unscaled: 0.1146 (0.1160)  loss_hw_unscaled: 0.0093 (0.0090)  loss_hw_0_unscaled: 0.0092 (0.0096)  loss_hw_1_unscaled: 0.0093 (0.0093)  loss_hw_2_unscaled: 0.0095 (0.0092)  loss_hw_3_unscaled: 0.0092 (0.0091)  loss_hw_4_unscaled: 0.0094 (0.0090)  loss_hw_interm_unscaled: 0.0103 (0.0100)  loss_xy_unscaled: 0.0058 (0.0056)  loss_xy_0_unscaled: 0.0058 (0.0058)  loss_xy_1_unscaled: 0.0057 (0.0057)  loss_xy_2_unscaled: 0.0056 (0.0057)  loss_xy_3_unscaled: 0.0057 (0.0056)  loss_xy_4_unscaled: 0.0054 (0.0056)  loss_xy_interm_unscaled: 0.0059 (0.0059)  time: 3.9483  data: 0.0165  max mem: 21141
Epoch: [14]  [ 70/302]  eta: 0:15:48  lr: 0.000000  loss: 2.6452 (2.8497)  loss_bbox: 0.0744 (0.0739)  loss_bbox_0: 0.0748 (0.0778)  loss_bbox_1: 0.0748 (0.0757)  loss_bbox_2: 0.0745 (0.0755)  loss_bbox_3: 0.0734 (0.0744)  loss_bbox_4: 0.0749 (0.0740)  loss_bbox_interm: 0.0763 (0.0801)  loss_ce: 0.0857 (0.1041)  loss_ce_0: 0.0992 (0.1162)  loss_ce_1: 0.0935 (0.1114)  loss_ce_2: 0.0891 (0.1062)  loss_ce_3: 0.0868 (0.1061)  loss_ce_4: 0.0849 (0.1043)  loss_ce_interm: 0.1277 (0.1369)  loss_giou: 0.2074 (0.2141)  loss_giou_0: 0.2113 (0.2225)  loss_giou_1: 0.2160 (0.2179)  loss_giou_2: 0.2130 (0.2175)  loss_giou_3: 0.2096 (0.2152)  loss_giou_4: 0.2081 (0.2140)  loss_giou_interm: 0.2179 (0.2319)  loss_bbox_unscaled: 0.0149 (0.0148)  loss_bbox_0_unscaled: 0.0150 (0.0156)  loss_bbox_1_unscaled: 0.0150 (0.0151)  loss_bbox_2_unscaled: 0.0149 (0.0151)  loss_bbox_3_unscaled: 0.0147 (0.0149)  loss_bbox_4_unscaled: 0.0150 (0.0148)  loss_bbox_interm_unscaled: 0.0153 (0.0160)  loss_ce_unscaled: 0.0428 (0.0521)  loss_ce_0_unscaled: 0.0496 (0.0581)  loss_ce_1_unscaled: 0.0468 (0.0557)  loss_ce_2_unscaled: 0.0446 (0.0531)  loss_ce_3_unscaled: 0.0434 (0.0530)  loss_ce_4_unscaled: 0.0425 (0.0521)  loss_ce_interm_unscaled: 0.0638 (0.0684)  loss_giou_unscaled: 0.1037 (0.1070)  loss_giou_0_unscaled: 0.1056 (0.1113)  loss_giou_1_unscaled: 0.1080 (0.1089)  loss_giou_2_unscaled: 0.1065 (0.1087)  loss_giou_3_unscaled: 0.1048 (0.1076)  loss_giou_4_unscaled: 0.1040 (0.1070)  loss_giou_interm_unscaled: 0.1090 (0.1160)  loss_hw_unscaled: 0.0092 (0.0092)  loss_hw_0_unscaled: 0.0092 (0.0097)  loss_hw_1_unscaled: 0.0093 (0.0094)  loss_hw_2_unscaled: 0.0094 (0.0094)  loss_hw_3_unscaled: 0.0092 (0.0092)  loss_hw_4_unscaled: 0.0092 (0.0092)  loss_hw_interm_unscaled: 0.0100 (0.0101)  loss_xy_unscaled: 0.0057 (0.0056)  loss_xy_0_unscaled: 0.0055 (0.0058)  loss_xy_1_unscaled: 0.0057 (0.0057)  loss_xy_2_unscaled: 0.0057 (0.0057)  loss_xy_3_unscaled: 0.0057 (0.0056)  loss_xy_4_unscaled: 0.0058 (0.0056)  loss_xy_interm_unscaled: 0.0055 (0.0059)  time: 4.1977  data: 0.0269  max mem: 21141
Epoch: [14]  [ 80/302]  eta: 0:15:05  lr: 0.000000  loss: 2.8956 (2.8808)  loss_bbox: 0.0744 (0.0745)  loss_bbox_0: 0.0806 (0.0785)  loss_bbox_1: 0.0769 (0.0762)  loss_bbox_2: 0.0771 (0.0760)  loss_bbox_3: 0.0737 (0.0749)  loss_bbox_4: 0.0749 (0.0746)  loss_bbox_interm: 0.0818 (0.0807)  loss_ce: 0.1108 (0.1072)  loss_ce_0: 0.1191 (0.1213)  loss_ce_1: 0.1124 (0.1159)  loss_ce_2: 0.1120 (0.1097)  loss_ce_3: 0.1106 (0.1092)  loss_ce_4: 0.1142 (0.1071)  loss_ce_interm: 0.1345 (0.1409)  loss_giou: 0.2112 (0.2144)  loss_giou_0: 0.2179 (0.2224)  loss_giou_1: 0.2157 (0.2178)  loss_giou_2: 0.2134 (0.2175)  loss_giou_3: 0.2130 (0.2155)  loss_giou_4: 0.2086 (0.2147)  loss_giou_interm: 0.2295 (0.2319)  loss_bbox_unscaled: 0.0149 (0.0149)  loss_bbox_0_unscaled: 0.0161 (0.0157)  loss_bbox_1_unscaled: 0.0154 (0.0152)  loss_bbox_2_unscaled: 0.0154 (0.0152)  loss_bbox_3_unscaled: 0.0147 (0.0150)  loss_bbox_4_unscaled: 0.0150 (0.0149)  loss_bbox_interm_unscaled: 0.0164 (0.0161)  loss_ce_unscaled: 0.0554 (0.0536)  loss_ce_0_unscaled: 0.0596 (0.0607)  loss_ce_1_unscaled: 0.0562 (0.0579)  loss_ce_2_unscaled: 0.0560 (0.0548)  loss_ce_3_unscaled: 0.0553 (0.0546)  loss_ce_4_unscaled: 0.0571 (0.0536)  loss_ce_interm_unscaled: 0.0672 (0.0705)  loss_giou_unscaled: 0.1056 (0.1072)  loss_giou_0_unscaled: 0.1089 (0.1112)  loss_giou_1_unscaled: 0.1079 (0.1089)  loss_giou_2_unscaled: 0.1067 (0.1087)  loss_giou_3_unscaled: 0.1065 (0.1077)  loss_giou_4_unscaled: 0.1043 (0.1073)  loss_giou_interm_unscaled: 0.1147 (0.1159)  loss_hw_unscaled: 0.0092 (0.0092)  loss_hw_0_unscaled: 0.0102 (0.0098)  loss_hw_1_unscaled: 0.0098 (0.0095)  loss_hw_2_unscaled: 0.0096 (0.0094)  loss_hw_3_unscaled: 0.0094 (0.0093)  loss_hw_4_unscaled: 0.0092 (0.0093)  loss_hw_interm_unscaled: 0.0105 (0.0102)  loss_xy_unscaled: 0.0057 (0.0057)  loss_xy_0_unscaled: 0.0061 (0.0059)  loss_xy_1_unscaled: 0.0059 (0.0058)  loss_xy_2_unscaled: 0.0058 (0.0058)  loss_xy_3_unscaled: 0.0056 (0.0057)  loss_xy_4_unscaled: 0.0057 (0.0057)  loss_xy_interm_unscaled: 0.0061 (0.0060)  time: 4.2543  data: 0.0264  max mem: 21141
