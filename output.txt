world size: 2, rank: 1, local rank: 1
{
  "SHELL": "/bin/bash",
  "COLORTERM": "truecolor",
  "VSCODE_DEBUGPY_ADAPTER_ENDPOINTS": "/isis/home/hasana3/.vscode-server/extensions/ms-python.debugpy-2025.14.1-linux-x64/.noConfigDebugAdapterEndpoints/endpoint-185d3397b17aca33.txt",
  "TERM_PROGRAM_VERSION": "1.105.0",
  "CONDA_EXE": "/isis/home/hasana3/miniconda3/bin/conda",
  "_CE_M": "",
  "TERMCAP": "SC|screen.xterm-256color|VT 100/ANSI X3.64 virtual terminal:DO=\\E[%dB:LE=\\E[%dD:RI=\\E[%dC:UP=\\E[%dA:bs:bt=\\E[Z:cd=\\E[J:ce=\\E[K:cl=\\E[H\\E[J:cm=\\E[%i%d;%dH:ct=\\E[3g:do=^J:nd=\\E[C:pt:rc=\\E8:rs=\\Ec:sc=\\E7:st=\\EH:up=\\EM:le=^H:bl=^G:cr=^M:it#8:ho=\\E[H:nw=\\EE:ta=^I:is=\\E)0:li#14:co#135:am:xn:xv:LP:sr=\\EM:al=\\E[L:AL=\\E[%dL:cs=\\E[%i%d;%dr:dl=\\E[M:DL=\\E[%dM:dc=\\E[P:DC=\\E[%dP:im=\\E[4h:ei=\\E[4l:mi:IC=\\E[%d@:ks=\\E[?1h\\E=:ke=\\E[?1l\\E>:vi=\\E[?25l:ve=\\E[34h\\E[?25h:vs=\\E[34l:ti=\\E[?1049h:te=\\E[?1049l:us=\\E[4m:ue=\\E[24m:so=\\E[3m:se=\\E[23m:mb=\\E[5m:md=\\E[1m:mh=\\E[2m:mr=\\E[7m:me=\\E[m:ms:Co#8:pa#64:AF=\\E[3%dm:AB=\\E[4%dm:op=\\E[39;49m:AX:vb=\\Eg:G0:as=\\E(0:ae=\\E(B:ac=\\140\\140aaffggjjkkllmmnnooppqqrrssttuuvvwwxxyyzz{{||}}~~..--++,,hhII00:po=\\E[5i:pf=\\E[4i:Km=\\E[<:k0=\\E[10~:k1=\\EOP:k2=\\EOQ:k3=\\EOR:k4=\\EOS:k5=\\E[15~:k6=\\E[17~:k7=\\E[18~:k8=\\E[19~:k9=\\E[20~:k;=\\E[21~:F1=\\E[23~:F2=\\E[24~:kB=\\E[Z:kh=\\E[1~:@1=\\E[1~:kH=\\E[4~:@7=\\E[4~:kN=\\E[6~:kP=\\E[5~:kI=\\E[2~:kD=\\E[3~:ku=\\EOA:kd=\\EOB:kr=\\EOC:kl=\\EOD:km:",
  "WINDOW": "0",
  "PYDEVD_DISABLE_FILE_VALIDATION": "1",
  "PWD": "/isis/home/hasana3/Open-GroundingDino",
  "LOGNAME": "hasana3",
  "XDG_SESSION_TYPE": "tty",
  "CONDA_PREFIX": "/isis/home/hasana3/miniconda3/envs/dino_train",
  "BUNDLED_DEBUGPY_PATH": "/isis/home/hasana3/.vscode-server/extensions/ms-python.debugpy-2025.14.1-linux-x64/bundled/libs/debugpy",
  "VSCODE_GIT_ASKPASS_NODE": "/isis/home/hasana3/.vscode-server/bin/03c265b1adee71ac88f833e065f7bb956b60550a/node",
  "MOTD_SHOWN": "pam",
  "TOKENIZERS_PARALLELISM": "false",
  "HOME": "/isis/home/hasana3",
  "LANG": "en_US.UTF-8",
  "LS_COLORS": "rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.zst=01;31:*.tzst=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.wim=01;31:*.swm=01;31:*.dwm=01;31:*.esd=01;31:*.jpg=01;35:*.jpeg=01;35:*.mjpg=01;35:*.mjpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.webp=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36:",
  "PYTHONSTARTUP": "/isis/home/hasana3/.vscode-server/data/User/workspaceStorage/2cf3e39fb37d19ba286440928e92b7b0/ms-python.python/pythonrc.py",
  "CONDA_PROMPT_MODIFIER": "(dino_train) ",
  "GIT_ASKPASS": "/isis/home/hasana3/.vscode-server/bin/03c265b1adee71ac88f833e065f7bb956b60550a/extensions/git/dist/askpass.sh",
  "SSH_CONNECTION": "10.52.131.83 49217 10.2.218.246 22",
  "VSCODE_GIT_ASKPASS_EXTRA_ARGS": "",
  "CUDA_VISIBLE_DEVICES": "0,1",
  "VSCODE_PYTHON_AUTOACTIVATE_GUARD": "1",
  "XDG_SESSION_CLASS": "user",
  "PYTHONPATH": "/isis/home/hasana3/Open-GroundingDino/:",
  "TERM": "screen.xterm-256color",
  "PYTHON_BASIC_REPL": "1",
  "_CE_CONDA": "",
  "USER": "hasana3",
  "VSCODE_GIT_IPC_HANDLE": "/run/user/20007/vscode-git-6cdc07a7c5.sock",
  "CONDA_SHLVL": "1",
  "SHLVL": "3",
  "XDG_SESSION_ID": "1073",
  "CONDA_PYTHON_EXE": "/isis/home/hasana3/miniconda3/bin/python",
  "LD_LIBRARY_PATH": "/usr/lib/nvidia-cuda-toolkit/lib64:/usr/lib/nvidia-cuda-toolkit/lib64:/usr/lib/nvidia-cuda-toolkit/lib64:",
  "XDG_RUNTIME_DIR": "/run/user/20007",
  "SSH_CLIENT": "10.52.131.83 49217 22",
  "CONDA_DEFAULT_ENV": "dino_train",
  "LC_ALL": "en_US.UTF-8",
  "VSCODE_GIT_ASKPASS_MAIN": "/isis/home/hasana3/.vscode-server/bin/03c265b1adee71ac88f833e065f7bb956b60550a/extensions/git/dist/askpass-main.js",
  "CUDA_HOME": "/usr/lib/nvidia-cuda-toolkit",
  "XDG_DATA_DIRS": "/usr/share/gnome:/usr/local/share:/usr/share:/var/lib/snapd/desktop",
  "BROWSER": "/isis/home/hasana3/.vscode-server/bin/03c265b1adee71ac88f833e065f7bb956b60550a/bin/helpers/browser.sh",
  "PATH": "/usr/lib/nvidia-cuda-toolkit/bin:/opt/ros/humble/bin:/isis/home/hasana3/miniconda3/envs/dino_train/bin:/usr/lib/nvidia-cuda-toolkit/bin:/opt/ros/humble/bin:/isis/home/hasana3/.vscode-server/bin/03c265b1adee71ac88f833e065f7bb956b60550a/bin/remote-cli:/isis/home/hasana3/.local/bin:/usr/lib/nvidia-cuda-toolkit/bin:/isis/home/hasana3/miniconda3/condabin:/opt/ros/humble/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/isis/home/hasana3/.vscode-server/data/User/globalStorage/github.copilot-chat/debugCommand:/isis/home/hasana3/.vscode-server/extensions/ms-python.debugpy-2025.14.1-linux-x64/bundled/scripts/noConfigScripts",
  "STY": "1667706.dinotrain",
  "DBUS_SESSION_BUS_ADDRESS": "unix:path=/run/user/20007/bus",
  "OLDPWD": "/isis/home/hasana3/Open-GroundingDino",
  "TERM_PROGRAM": "vscode",
  "VSCODE_IPC_HOOK_CLI": "/run/user/20007/vscode-ipc-9f40d549-e61e-4ab5-9b2e-19847a3acd00.sock",
  "_": "/isis/home/hasana3/miniconda3/envs/dino_train/bin/python",
  "OMP_NUM_THREADS": "1",
  "LOCAL_RANK": "1",
  "RANK": "1",
  "GROUP_RANK": "0",
  "ROLE_RANK": "1",
  "ROLE_NAME": "default",
  "LOCAL_WORLD_SIZE": "2",
  "WORLD_SIZE": "2",
  "GROUP_WORLD_SIZE": "1",
  "ROLE_WORLD_SIZE": "2",
  "MASTER_ADDR": "127.0.0.1",
  "MASTER_PORT": "29500",
  "TORCHELASTIC_RESTART_COUNT": "0",
  "TORCHELASTIC_MAX_RESTARTS": "0",
  "TORCHELASTIC_RUN_ID": "none",
  "TORCHELASTIC_USE_AGENT_STORE": "True",
  "NCCL_ASYNC_ERROR_HANDLING": "1",
  "TORCHELASTIC_ERROR_FILE": "/tmp/torchelastic_uid51l8l/none_04udbqrj/attempt_0/1/error.json"
}
world size: 2, rank: 0, local rank: 0
{
  "SHELL": "/bin/bash",
  "COLORTERM": "truecolor",
  "VSCODE_DEBUGPY_ADAPTER_ENDPOINTS": "/isis/home/hasana3/.vscode-server/extensions/ms-python.debugpy-2025.14.1-linux-x64/.noConfigDebugAdapterEndpoints/endpoint-185d3397b17aca33.txt",
  "TERM_PROGRAM_VERSION": "1.105.0",
  "CONDA_EXE": "/isis/home/hasana3/miniconda3/bin/conda",
  "_CE_M": "",
  "TERMCAP": "SC|screen.xterm-256color|VT 100/ANSI X3.64 virtual terminal:DO=\\E[%dB:LE=\\E[%dD:RI=\\E[%dC:UP=\\E[%dA:bs:bt=\\E[Z:cd=\\E[J:ce=\\E[K:cl=\\E[H\\E[J:cm=\\E[%i%d;%dH:ct=\\E[3g:do=^J:nd=\\E[C:pt:rc=\\E8:rs=\\Ec:sc=\\E7:st=\\EH:up=\\EM:le=^H:bl=^G:cr=^M:it#8:ho=\\E[H:nw=\\EE:ta=^I:is=\\E)0:li#14:co#135:am:xn:xv:LP:sr=\\EM:al=\\E[L:AL=\\E[%dL:cs=\\E[%i%d;%dr:dl=\\E[M:DL=\\E[%dM:dc=\\E[P:DC=\\E[%dP:im=\\E[4h:ei=\\E[4l:mi:IC=\\E[%d@:ks=\\E[?1h\\E=:ke=\\E[?1l\\E>:vi=\\E[?25l:ve=\\E[34h\\E[?25h:vs=\\E[34l:ti=\\E[?1049h:te=\\E[?1049l:us=\\E[4m:ue=\\E[24m:so=\\E[3m:se=\\E[23m:mb=\\E[5m:md=\\E[1m:mh=\\E[2m:mr=\\E[7m:me=\\E[m:ms:Co#8:pa#64:AF=\\E[3%dm:AB=\\E[4%dm:op=\\E[39;49m:AX:vb=\\Eg:G0:as=\\E(0:ae=\\E(B:ac=\\140\\140aaffggjjkkllmmnnooppqqrrssttuuvvwwxxyyzz{{||}}~~..--++,,hhII00:po=\\E[5i:pf=\\E[4i:Km=\\E[<:k0=\\E[10~:k1=\\EOP:k2=\\EOQ:k3=\\EOR:k4=\\EOS:k5=\\E[15~:k6=\\E[17~:k7=\\E[18~:k8=\\E[19~:k9=\\E[20~:k;=\\E[21~:F1=\\E[23~:F2=\\E[24~:kB=\\E[Z:kh=\\E[1~:@1=\\E[1~:kH=\\E[4~:@7=\\E[4~:kN=\\E[6~:kP=\\E[5~:kI=\\E[2~:kD=\\E[3~:ku=\\EOA:kd=\\EOB:kr=\\EOC:kl=\\EOD:km:",
  "WINDOW": "0",
  "PYDEVD_DISABLE_FILE_VALIDATION": "1",
  "PWD": "/isis/home/hasana3/Open-GroundingDino",
  "LOGNAME": "hasana3",
  "XDG_SESSION_TYPE": "tty",
  "CONDA_PREFIX": "/isis/home/hasana3/miniconda3/envs/dino_train",
  "BUNDLED_DEBUGPY_PATH": "/isis/home/hasana3/.vscode-server/extensions/ms-python.debugpy-2025.14.1-linux-x64/bundled/libs/debugpy",
  "VSCODE_GIT_ASKPASS_NODE": "/isis/home/hasana3/.vscode-server/bin/03c265b1adee71ac88f833e065f7bb956b60550a/node",
  "MOTD_SHOWN": "pam",
  "TOKENIZERS_PARALLELISM": "false",
  "HOME": "/isis/home/hasana3",
  "LANG": "en_US.UTF-8",
  "LS_COLORS": "rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.zst=01;31:*.tzst=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.wim=01;31:*.swm=01;31:*.dwm=01;31:*.esd=01;31:*.jpg=01;35:*.jpeg=01;35:*.mjpg=01;35:*.mjpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.webp=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36:",
  "PYTHONSTARTUP": "/isis/home/hasana3/.vscode-server/data/User/workspaceStorage/2cf3e39fb37d19ba286440928e92b7b0/ms-python.python/pythonrc.py",
  "CONDA_PROMPT_MODIFIER": "(dino_train) ",
  "GIT_ASKPASS": "/isis/home/hasana3/.vscode-server/bin/03c265b1adee71ac88f833e065f7bb956b60550a/extensions/git/dist/askpass.sh",
  "SSH_CONNECTION": "10.52.131.83 49217 10.2.218.246 22",
  "VSCODE_GIT_ASKPASS_EXTRA_ARGS": "",
  "CUDA_VISIBLE_DEVICES": "0,1",
  "VSCODE_PYTHON_AUTOACTIVATE_GUARD": "1",
  "XDG_SESSION_CLASS": "user",
  "PYTHONPATH": "/isis/home/hasana3/Open-GroundingDino/:",
  "TERM": "screen.xterm-256color",
  "PYTHON_BASIC_REPL": "1",
  "_CE_CONDA": "",
  "USER": "hasana3",
  "VSCODE_GIT_IPC_HANDLE": "/run/user/20007/vscode-git-6cdc07a7c5.sock",
  "CONDA_SHLVL": "1",
  "SHLVL": "3",
  "XDG_SESSION_ID": "1073",
  "CONDA_PYTHON_EXE": "/isis/home/hasana3/miniconda3/bin/python",
  "LD_LIBRARY_PATH": "/usr/lib/nvidia-cuda-toolkit/lib64:/usr/lib/nvidia-cuda-toolkit/lib64:/usr/lib/nvidia-cuda-toolkit/lib64:",
  "XDG_RUNTIME_DIR": "/run/user/20007",
  "SSH_CLIENT": "10.52.131.83 49217 22",
  "CONDA_DEFAULT_ENV": "dino_train",
  "LC_ALL": "en_US.UTF-8",
  "VSCODE_GIT_ASKPASS_MAIN": "/isis/home/hasana3/.vscode-server/bin/03c265b1adee71ac88f833e065f7bb956b60550a/extensions/git/dist/askpass-main.js",
  "CUDA_HOME": "/usr/lib/nvidia-cuda-toolkit",
  "XDG_DATA_DIRS": "/usr/share/gnome:/usr/local/share:/usr/share:/var/lib/snapd/desktop",
  "BROWSER": "/isis/home/hasana3/.vscode-server/bin/03c265b1adee71ac88f833e065f7bb956b60550a/bin/helpers/browser.sh",
  "PATH": "/usr/lib/nvidia-cuda-toolkit/bin:/opt/ros/humble/bin:/isis/home/hasana3/miniconda3/envs/dino_train/bin:/usr/lib/nvidia-cuda-toolkit/bin:/opt/ros/humble/bin:/isis/home/hasana3/.vscode-server/bin/03c265b1adee71ac88f833e065f7bb956b60550a/bin/remote-cli:/isis/home/hasana3/.local/bin:/usr/lib/nvidia-cuda-toolkit/bin:/isis/home/hasana3/miniconda3/condabin:/opt/ros/humble/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/isis/home/hasana3/.vscode-server/data/User/globalStorage/github.copilot-chat/debugCommand:/isis/home/hasana3/.vscode-server/extensions/ms-python.debugpy-2025.14.1-linux-x64/bundled/scripts/noConfigScripts",
  "STY": "1667706.dinotrain",
  "DBUS_SESSION_BUS_ADDRESS": "unix:path=/run/user/20007/bus",
  "OLDPWD": "/isis/home/hasana3/Open-GroundingDino",
  "TERM_PROGRAM": "vscode",
  "VSCODE_IPC_HOOK_CLI": "/run/user/20007/vscode-ipc-9f40d549-e61e-4ab5-9b2e-19847a3acd00.sock",
  "_": "/isis/home/hasana3/miniconda3/envs/dino_train/bin/python",
  "OMP_NUM_THREADS": "1",
  "LOCAL_RANK": "0",
  "RANK": "0",
  "GROUP_RANK": "0",
  "ROLE_RANK": "0",
  "ROLE_NAME": "default",
  "LOCAL_WORLD_SIZE": "2",
  "WORLD_SIZE": "2",
  "GROUP_WORLD_SIZE": "1",
  "ROLE_WORLD_SIZE": "2",
  "MASTER_ADDR": "127.0.0.1",
  "MASTER_PORT": "29500",
  "TORCHELASTIC_RESTART_COUNT": "0",
  "TORCHELASTIC_MAX_RESTARTS": "0",
  "TORCHELASTIC_RUN_ID": "none",
  "TORCHELASTIC_USE_AGENT_STORE": "True",
  "NCCL_ASYNC_ERROR_HANDLING": "1",
  "TORCHELASTIC_ERROR_FILE": "/tmp/torchelastic_uid51l8l/none_04udbqrj/attempt_0/0/error.json"
}
  == distributed init (rank 1) done.  == distributed init (rank 0) done.

Loading config file from config/GroundingDINO_SwinB_cfg.py
[32mINFO    [0m [32m2025-10-24 01:53:39,622 | [34mgit:
  sha: 03040d37d4ba3939321abac882ae6c65a7cf42db, status: has uncommited changes, branch: main
[0m
[32mINFO    [0m [32m2025-10-24 01:53:39,623 | [34mCommand: main.py --local_rank=0 -c config/GroundingDINO_SwinB_cfg.py --datasets dataset_meta_kitti.json --output_dir ../vlmtest/GroundingDINO/output/kitti_swinb_finetune --pretrain_model_path ../vlmtest/GroundingDINO/weights/groundingdino_swinb_cogcoor.pth --num_workers 32 --options lr=1e-4 batch_size=8 epochs=100 use_coco_eval=False[0m
[32mINFO    [0m [32m2025-10-24 01:53:39,623 | [34mFull config saved to ../vlmtest/GroundingDINO/output/kitti_swinb_finetune/config_args_all.json[0m
[32mINFO    [0m [32m2025-10-24 01:53:39,624 | [34mworld size: 2[0m
[32mINFO    [0m [32m2025-10-24 01:53:39,624 | [34mrank: 0[0m
[32mINFO    [0m [32m2025-10-24 01:53:39,624 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2025-10-24 01:53:39,624 | [34margs: Namespace(config_file='config/GroundingDINO_SwinB_cfg.py', options={'lr': 0.0001, 'batch_size': 8, 'epochs': 100, 'use_coco_eval': False}, datasets='dataset_meta_kitti.json', remove_difficult=False, fix_size=False, output_dir='../vlmtest/GroundingDINO/output/kitti_swinb_finetune', note='', device='cuda', seed=42, resume='', pretrain_model_path='../vlmtest/GroundingDINO/weights/groundingdino_swinb_cogcoor.pth', finetune_ignore=None, start_epoch=0, eval=False, num_workers=32, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=2, dist_url='env://', rank=0, local_rank=0, amp=False, gpu=0, distributed=True, dist_backend='nccl', batch_size=8, modelname='groundingdino', backbone='swin_B_384_22k', position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, num_feature_levels=4, enc_n_points=4, dec_n_points=4, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, transformer_activation='relu', dec_pred_bbox_embed_share=True, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, dn_label_coef=1.0, dn_bbox_coef=1.0, embed_init_tgt=True, dn_labelbook_size=2000, max_text_len=256, text_encoder_type='bert-base-uncased', use_text_enhancer=True, use_fusion_layer=True, use_checkpoint=True, use_transformer_ckpt=True, use_text_cross_attention=True, text_dropout=0.0, fusion_dropout=0.0, fusion_droppath=0.1, sub_sentence_present=True, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, max_labels=50, lr=0.0001, freeze_keywords=['bert'], lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], weight_decay=0.0001, param_dict_type='ddetr_in_mmdet', ddetr_lr_param=False, epochs=100, lr_drop=4, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[4, 8], frozen_weights=None, dilation=False, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=1.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=2.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, mask_loss_coef=1.0, dice_loss_coef=1.0, focal_alpha=0.25, focal_gamma=2.0, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_class_embed_share=True, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, use_coco_eval=False, dn_scalar=100, label_list=['car', 'pedestrian'])
[0m
[36mDEBUG   [0m [36m2025-10-24 01:53:39,625 | [34mbuild model ... ...[0m
final text_encoder_type: bert-base-uncased
load tokenizer done.
final text_encoder_type: bert-base-uncased
load tokenizer done.
[36mDEBUG   [0m [36m2025-10-24 01:53:41,497 | [34mbuild model, done.[0m
[32mINFO    [0m [32m2025-10-24 01:53:41,539 | [34mnumber of params:232313216[0m
[32mINFO    [0m [32m2025-10-24 01:53:41,541 | [34mparams before freezing:
{
  "module.transformer.level_embed": 1024,
  "module.transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.0.norm1.weight": 256,
  "module.transformer.encoder.layers.0.norm1.bias": 256,
  "module.transformer.encoder.layers.0.linear1.weight": 524288,
  "module.transformer.encoder.layers.0.linear1.bias": 2048,
  "module.transformer.encoder.layers.0.linear2.weight": 524288,
  "module.transformer.encoder.layers.0.linear2.bias": 256,
  "module.transformer.encoder.layers.0.norm2.weight": 256,
  "module.transformer.encoder.layers.0.norm2.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.1.norm1.weight": 256,
  "module.transformer.encoder.layers.1.norm1.bias": 256,
  "module.transformer.encoder.layers.1.linear1.weight": 524288,
  "module.transformer.encoder.layers.1.linear1.bias": 2048,
  "module.transformer.encoder.layers.1.linear2.weight": 524288,
  "module.transformer.encoder.layers.1.linear2.bias": 256,
  "module.transformer.encoder.layers.1.norm2.weight": 256,
  "module.transformer.encoder.layers.1.norm2.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.2.norm1.weight": 256,
  "module.transformer.encoder.layers.2.norm1.bias": 256,
  "module.transformer.encoder.layers.2.linear1.weight": 524288,
  "module.transformer.encoder.layers.2.linear1.bias": 2048,
  "module.transformer.encoder.layers.2.linear2.weight": 524288,
  "module.transformer.encoder.layers.2.linear2.bias": 256,
  "module.transformer.encoder.layers.2.norm2.weight": 256,
  "module.transformer.encoder.layers.2.norm2.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.3.norm1.weight": 256,
  "module.transformer.encoder.layers.3.norm1.bias": 256,
  "module.transformer.encoder.layers.3.linear1.weight": 524288,
  "module.transformer.encoder.layers.3.linear1.bias": 2048,
  "module.transformer.encoder.layers.3.linear2.weight": 524288,
  "module.transformer.encoder.layers.3.linear2.bias": 256,
  "module.transformer.encoder.layers.3.norm2.weight": 256,
  "module.transformer.encoder.layers.3.norm2.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.4.norm1.weight": 256,
  "module.transformer.encoder.layers.4.norm1.bias": 256,
  "module.transformer.encoder.layers.4.linear1.weight": 524288,
  "module.transformer.encoder.layers.4.linear1.bias": 2048,
  "module.transformer.encoder.layers.4.linear2.weight": 524288,
  "module.transformer.encoder.layers.4.linear2.bias": 256,
  "module.transformer.encoder.layers.4.norm2.weight": 256,
  "module.transformer.encoder.layers.4.norm2.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.5.norm1.weight": 256,
  "module.transformer.encoder.layers.5.norm1.bias": 256,
  "module.transformer.encoder.layers.5.linear1.weight": 524288,
  "module.transformer.encoder.layers.5.linear1.bias": 2048,
  "module.transformer.encoder.layers.5.linear2.weight": 524288,
  "module.transformer.encoder.layers.5.linear2.bias": 256,
  "module.transformer.encoder.layers.5.norm2.weight": 256,
  "module.transformer.encoder.layers.5.norm2.bias": 256,
  "module.transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.0.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.0.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.0.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.0.linear2.bias": 256,
  "module.transformer.encoder.text_layers.0.norm1.weight": 256,
  "module.transformer.encoder.text_layers.0.norm1.bias": 256,
  "module.transformer.encoder.text_layers.0.norm2.weight": 256,
  "module.transformer.encoder.text_layers.0.norm2.bias": 256,
  "module.transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.1.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.1.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.1.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.1.linear2.bias": 256,
  "module.transformer.encoder.text_layers.1.norm1.weight": 256,
  "module.transformer.encoder.text_layers.1.norm1.bias": 256,
  "module.transformer.encoder.text_layers.1.norm2.weight": 256,
  "module.transformer.encoder.text_layers.1.norm2.bias": 256,
  "module.transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.2.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.2.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.2.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.2.linear2.bias": 256,
  "module.transformer.encoder.text_layers.2.norm1.weight": 256,
  "module.transformer.encoder.text_layers.2.norm1.bias": 256,
  "module.transformer.encoder.text_layers.2.norm2.weight": 256,
  "module.transformer.encoder.text_layers.2.norm2.bias": 256,
  "module.transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.3.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.3.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.3.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.3.linear2.bias": 256,
  "module.transformer.encoder.text_layers.3.norm1.weight": 256,
  "module.transformer.encoder.text_layers.3.norm1.bias": 256,
  "module.transformer.encoder.text_layers.3.norm2.weight": 256,
  "module.transformer.encoder.text_layers.3.norm2.bias": 256,
  "module.transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.4.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.4.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.4.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.4.linear2.bias": 256,
  "module.transformer.encoder.text_layers.4.norm1.weight": 256,
  "module.transformer.encoder.text_layers.4.norm1.bias": 256,
  "module.transformer.encoder.text_layers.4.norm2.weight": 256,
  "module.transformer.encoder.text_layers.4.norm2.bias": 256,
  "module.transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.5.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.5.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.5.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.5.linear2.bias": 256,
  "module.transformer.encoder.text_layers.5.norm1.weight": 256,
  "module.transformer.encoder.text_layers.5.norm1.bias": 256,
  "module.transformer.encoder.text_layers.5.norm2.weight": 256,
  "module.transformer.encoder.text_layers.5.norm2.bias": 256,
  "module.transformer.encoder.fusion_layers.0.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.0.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.1.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.1.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.2.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.2.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.3.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.3.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.4.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.4.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.5.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.5.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.0.norm1.weight": 256,
  "module.transformer.decoder.layers.0.norm1.bias": 256,
  "module.transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.0.catext_norm.weight": 256,
  "module.transformer.decoder.layers.0.catext_norm.bias": 256,
  "module.transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.0.norm2.weight": 256,
  "module.transformer.decoder.layers.0.norm2.bias": 256,
  "module.transformer.decoder.layers.0.linear1.weight": 524288,
  "module.transformer.decoder.layers.0.linear1.bias": 2048,
  "module.transformer.decoder.layers.0.linear2.weight": 524288,
  "module.transformer.decoder.layers.0.linear2.bias": 256,
  "module.transformer.decoder.layers.0.norm3.weight": 256,
  "module.transformer.decoder.layers.0.norm3.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.1.norm1.weight": 256,
  "module.transformer.decoder.layers.1.norm1.bias": 256,
  "module.transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.1.catext_norm.weight": 256,
  "module.transformer.decoder.layers.1.catext_norm.bias": 256,
  "module.transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.1.norm2.weight": 256,
  "module.transformer.decoder.layers.1.norm2.bias": 256,
  "module.transformer.decoder.layers.1.linear1.weight": 524288,
  "module.transformer.decoder.layers.1.linear1.bias": 2048,
  "module.transformer.decoder.layers.1.linear2.weight": 524288,
  "module.transformer.decoder.layers.1.linear2.bias": 256,
  "module.transformer.decoder.layers.1.norm3.weight": 256,
  "module.transformer.decoder.layers.1.norm3.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.2.norm1.weight": 256,
  "module.transformer.decoder.layers.2.norm1.bias": 256,
  "module.transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.2.catext_norm.weight": 256,
  "module.transformer.decoder.layers.2.catext_norm.bias": 256,
  "module.transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.2.norm2.weight": 256,
  "module.transformer.decoder.layers.2.norm2.bias": 256,
  "module.transformer.decoder.layers.2.linear1.weight": 524288,
  "module.transformer.decoder.layers.2.linear1.bias": 2048,
  "module.transformer.decoder.layers.2.linear2.weight": 524288,
  "module.transformer.decoder.layers.2.linear2.bias": 256,
  "module.transformer.decoder.layers.2.norm3.weight": 256,
  "module.transformer.decoder.layers.2.norm3.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.3.norm1.weight": 256,
  "module.transformer.decoder.layers.3.norm1.bias": 256,
  "module.transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.3.catext_norm.weight": 256,
  "module.transformer.decoder.layers.3.catext_norm.bias": 256,
  "module.transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.3.norm2.weight": 256,
  "module.transformer.decoder.layers.3.norm2.bias": 256,
  "module.transformer.decoder.layers.3.linear1.weight": 524288,
  "module.transformer.decoder.layers.3.linear1.bias": 2048,
  "module.transformer.decoder.layers.3.linear2.weight": 524288,
  "module.transformer.decoder.layers.3.linear2.bias": 256,
  "module.transformer.decoder.layers.3.norm3.weight": 256,
  "module.transformer.decoder.layers.3.norm3.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.4.norm1.weight": 256,
  "module.transformer.decoder.layers.4.norm1.bias": 256,
  "module.transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.4.catext_norm.weight": 256,
  "module.transformer.decoder.layers.4.catext_norm.bias": 256,
  "module.transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.4.norm2.weight": 256,
  "module.transformer.decoder.layers.4.norm2.bias": 256,
  "module.transformer.decoder.layers.4.linear1.weight": 524288,
  "module.transformer.decoder.layers.4.linear1.bias": 2048,
  "module.transformer.decoder.layers.4.linear2.weight": 524288,
  "module.transformer.decoder.layers.4.linear2.bias": 256,
  "module.transformer.decoder.layers.4.norm3.weight": 256,
  "module.transformer.decoder.layers.4.norm3.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.5.norm1.weight": 256,
  "module.transformer.decoder.layers.5.norm1.bias": 256,
  "module.transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.5.catext_norm.weight": 256,
  "module.transformer.decoder.layers.5.catext_norm.bias": 256,
  "module.transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.5.norm2.weight": 256,
  "module.transformer.decoder.layers.5.norm2.bias": 256,
  "module.transformer.decoder.layers.5.linear1.weight": 524288,
  "module.transformer.decoder.layers.5.linear1.bias": 2048,
  "module.transformer.decoder.layers.5.linear2.weight": 524288,
  "module.transformer.decoder.layers.5.linear2.bias": 256,
  "module.transformer.decoder.layers.5.norm3.weight": 256,
  "module.transformer.decoder.layers.5.norm3.bias": 256,
  "module.transformer.decoder.norm.weight": 256,
  "module.transformer.decoder.norm.bias": 256,
  "module.transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "module.transformer.decoder.ref_point_head.layers.0.bias": 256,
  "module.transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "module.transformer.decoder.ref_point_head.layers.1.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "module.transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "module.transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "module.transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "module.transformer.tgt_embed.weight": 230400,
  "module.transformer.enc_output.weight": 65536,
  "module.transformer.enc_output.bias": 256,
  "module.transformer.enc_output_norm.weight": 256,
  "module.transformer.enc_output_norm.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "module.transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "module.transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "module.transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "module.bert.embeddings.word_embeddings.weight": 23440896,
  "module.bert.embeddings.position_embeddings.weight": 393216,
  "module.bert.embeddings.token_type_embeddings.weight": 1536,
  "module.bert.embeddings.LayerNorm.weight": 768,
  "module.bert.embeddings.LayerNorm.bias": 768,
  "module.bert.encoder.layer.0.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.0.attention.self.query.bias": 768,
  "module.bert.encoder.layer.0.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.0.attention.self.key.bias": 768,
  "module.bert.encoder.layer.0.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.0.attention.self.value.bias": 768,
  "module.bert.encoder.layer.0.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.0.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.0.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.0.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.0.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.0.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.0.output.dense.weight": 2359296,
  "module.bert.encoder.layer.0.output.dense.bias": 768,
  "module.bert.encoder.layer.0.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.0.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.1.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.1.attention.self.query.bias": 768,
  "module.bert.encoder.layer.1.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.1.attention.self.key.bias": 768,
  "module.bert.encoder.layer.1.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.1.attention.self.value.bias": 768,
  "module.bert.encoder.layer.1.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.1.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.1.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.1.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.1.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.1.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.1.output.dense.weight": 2359296,
  "module.bert.encoder.layer.1.output.dense.bias": 768,
  "module.bert.encoder.layer.1.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.1.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.2.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.2.attention.self.query.bias": 768,
  "module.bert.encoder.layer.2.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.2.attention.self.key.bias": 768,
  "module.bert.encoder.layer.2.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.2.attention.self.value.bias": 768,
  "module.bert.encoder.layer.2.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.2.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.2.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.2.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.2.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.2.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.2.output.dense.weight": 2359296,
  "module.bert.encoder.layer.2.output.dense.bias": 768,
  "module.bert.encoder.layer.2.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.2.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.3.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.3.attention.self.query.bias": 768,
  "module.bert.encoder.layer.3.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.3.attention.self.key.bias": 768,
  "module.bert.encoder.layer.3.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.3.attention.self.value.bias": 768,
  "module.bert.encoder.layer.3.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.3.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.3.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.3.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.3.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.3.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.3.output.dense.weight": 2359296,
  "module.bert.encoder.layer.3.output.dense.bias": 768,
  "module.bert.encoder.layer.3.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.3.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.4.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.4.attention.self.query.bias": 768,
  "module.bert.encoder.layer.4.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.4.attention.self.key.bias": 768,
  "module.bert.encoder.layer.4.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.4.attention.self.value.bias": 768,
  "module.bert.encoder.layer.4.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.4.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.4.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.4.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.4.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.4.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.4.output.dense.weight": 2359296,
  "module.bert.encoder.layer.4.output.dense.bias": 768,
  "module.bert.encoder.layer.4.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.4.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.5.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.5.attention.self.query.bias": 768,
  "module.bert.encoder.layer.5.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.5.attention.self.key.bias": 768,
  "module.bert.encoder.layer.5.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.5.attention.self.value.bias": 768,
  "module.bert.encoder.layer.5.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.5.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.5.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.5.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.5.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.5.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.5.output.dense.weight": 2359296,
  "module.bert.encoder.layer.5.output.dense.bias": 768,
  "module.bert.encoder.layer.5.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.5.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.6.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.6.attention.self.query.bias": 768,
  "module.bert.encoder.layer.6.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.6.attention.self.key.bias": 768,
  "module.bert.encoder.layer.6.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.6.attention.self.value.bias": 768,
  "module.bert.encoder.layer.6.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.6.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.6.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.6.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.6.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.6.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.6.output.dense.weight": 2359296,
  "module.bert.encoder.layer.6.output.dense.bias": 768,
  "module.bert.encoder.layer.6.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.6.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.7.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.7.attention.self.query.bias": 768,
  "module.bert.encoder.layer.7.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.7.attention.self.key.bias": 768,
  "module.bert.encoder.layer.7.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.7.attention.self.value.bias": 768,
  "module.bert.encoder.layer.7.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.7.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.7.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.7.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.7.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.7.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.7.output.dense.weight": 2359296,
  "module.bert.encoder.layer.7.output.dense.bias": 768,
  "module.bert.encoder.layer.7.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.7.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.8.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.8.attention.self.query.bias": 768,
  "module.bert.encoder.layer.8.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.8.attention.self.key.bias": 768,
  "module.bert.encoder.layer.8.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.8.attention.self.value.bias": 768,
  "module.bert.encoder.layer.8.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.8.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.8.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.8.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.8.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.8.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.8.output.dense.weight": 2359296,
  "module.bert.encoder.layer.8.output.dense.bias": 768,
  "module.bert.encoder.layer.8.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.8.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.9.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.9.attention.self.query.bias": 768,
  "module.bert.encoder.layer.9.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.9.attention.self.key.bias": 768,
  "module.bert.encoder.layer.9.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.9.attention.self.value.bias": 768,
  "module.bert.encoder.layer.9.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.9.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.9.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.9.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.9.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.9.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.9.output.dense.weight": 2359296,
  "module.bert.encoder.layer.9.output.dense.bias": 768,
  "module.bert.encoder.layer.9.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.9.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.10.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.10.attention.self.query.bias": 768,
  "module.bert.encoder.layer.10.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.10.attention.self.key.bias": 768,
  "module.bert.encoder.layer.10.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.10.attention.self.value.bias": 768,
  "module.bert.encoder.layer.10.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.10.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.10.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.10.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.10.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.10.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.10.output.dense.weight": 2359296,
  "module.bert.encoder.layer.10.output.dense.bias": 768,
  "module.bert.encoder.layer.10.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.10.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.11.attention.self.query.weight": 589824,
  "module.bert.encoder.layer.11.attention.self.query.bias": 768,
  "module.bert.encoder.layer.11.attention.self.key.weight": 589824,
  "module.bert.encoder.layer.11.attention.self.key.bias": 768,
  "module.bert.encoder.layer.11.attention.self.value.weight": 589824,
  "module.bert.encoder.layer.11.attention.self.value.bias": 768,
  "module.bert.encoder.layer.11.attention.output.dense.weight": 589824,
  "module.bert.encoder.layer.11.attention.output.dense.bias": 768,
  "module.bert.encoder.layer.11.attention.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.11.attention.output.LayerNorm.bias": 768,
  "module.bert.encoder.layer.11.intermediate.dense.weight": 2359296,
  "module.bert.encoder.layer.11.intermediate.dense.bias": 3072,
  "module.bert.encoder.layer.11.output.dense.weight": 2359296,
  "module.bert.encoder.layer.11.output.dense.bias": 768,
  "module.bert.encoder.layer.11.output.LayerNorm.weight": 768,
  "module.bert.encoder.layer.11.output.LayerNorm.bias": 768,
  "module.feat_map.weight": 196608,
  "module.feat_map.bias": 256,
  "module.input_proj.0.0.weight": 65536,
  "module.input_proj.0.0.bias": 256,
  "module.input_proj.0.1.weight": 256,
  "module.input_proj.0.1.bias": 256,
  "module.input_proj.1.0.weight": 131072,
  "module.input_proj.1.0.bias": 256,
  "module.input_proj.1.1.weight": 256,
  "module.input_proj.1.1.bias": 256,
  "module.input_proj.2.0.weight": 262144,
  "module.input_proj.2.0.bias": 256,
  "module.input_proj.2.1.weight": 256,
  "module.input_proj.2.1.bias": 256,
  "module.input_proj.3.0.weight": 2359296,
  "module.input_proj.3.0.bias": 256,
  "module.input_proj.3.1.weight": 256,
  "module.input_proj.3.1.bias": 256,
  "module.backbone.0.patch_embed.proj.weight": 6144,
  "module.backbone.0.patch_embed.proj.bias": 128,
  "module.backbone.0.patch_embed.norm.weight": 128,
  "module.backbone.0.patch_embed.norm.bias": 128,
  "module.backbone.0.layers.0.blocks.0.norm1.weight": 128,
  "module.backbone.0.layers.0.blocks.0.norm1.bias": 128,
  "module.backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 2116,
  "module.backbone.0.layers.0.blocks.0.attn.qkv.weight": 49152,
  "module.backbone.0.layers.0.blocks.0.attn.qkv.bias": 384,
  "module.backbone.0.layers.0.blocks.0.attn.proj.weight": 16384,
  "module.backbone.0.layers.0.blocks.0.attn.proj.bias": 128,
  "module.backbone.0.layers.0.blocks.0.norm2.weight": 128,
  "module.backbone.0.layers.0.blocks.0.norm2.bias": 128,
  "module.backbone.0.layers.0.blocks.0.mlp.fc1.weight": 65536,
  "module.backbone.0.layers.0.blocks.0.mlp.fc1.bias": 512,
  "module.backbone.0.layers.0.blocks.0.mlp.fc2.weight": 65536,
  "module.backbone.0.layers.0.blocks.0.mlp.fc2.bias": 128,
  "module.backbone.0.layers.0.blocks.1.norm1.weight": 128,
  "module.backbone.0.layers.0.blocks.1.norm1.bias": 128,
  "module.backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 2116,
  "module.backbone.0.layers.0.blocks.1.attn.qkv.weight": 49152,
  "module.backbone.0.layers.0.blocks.1.attn.qkv.bias": 384,
  "module.backbone.0.layers.0.blocks.1.attn.proj.weight": 16384,
  "module.backbone.0.layers.0.blocks.1.attn.proj.bias": 128,
  "module.backbone.0.layers.0.blocks.1.norm2.weight": 128,
  "module.backbone.0.layers.0.blocks.1.norm2.bias": 128,
  "module.backbone.0.layers.0.blocks.1.mlp.fc1.weight": 65536,
  "module.backbone.0.layers.0.blocks.1.mlp.fc1.bias": 512,
  "module.backbone.0.layers.0.blocks.1.mlp.fc2.weight": 65536,
  "module.backbone.0.layers.0.blocks.1.mlp.fc2.bias": 128,
  "module.backbone.0.layers.0.downsample.reduction.weight": 131072,
  "module.backbone.0.layers.0.downsample.norm.weight": 512,
  "module.backbone.0.layers.0.downsample.norm.bias": 512,
  "module.backbone.0.layers.1.blocks.0.norm1.weight": 256,
  "module.backbone.0.layers.1.blocks.0.norm1.bias": 256,
  "module.backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 4232,
  "module.backbone.0.layers.1.blocks.0.attn.qkv.weight": 196608,
  "module.backbone.0.layers.1.blocks.0.attn.qkv.bias": 768,
  "module.backbone.0.layers.1.blocks.0.attn.proj.weight": 65536,
  "module.backbone.0.layers.1.blocks.0.attn.proj.bias": 256,
  "module.backbone.0.layers.1.blocks.0.norm2.weight": 256,
  "module.backbone.0.layers.1.blocks.0.norm2.bias": 256,
  "module.backbone.0.layers.1.blocks.0.mlp.fc1.weight": 262144,
  "module.backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1024,
  "module.backbone.0.layers.1.blocks.0.mlp.fc2.weight": 262144,
  "module.backbone.0.layers.1.blocks.0.mlp.fc2.bias": 256,
  "module.backbone.0.layers.1.blocks.1.norm1.weight": 256,
  "module.backbone.0.layers.1.blocks.1.norm1.bias": 256,
  "module.backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 4232,
  "module.backbone.0.layers.1.blocks.1.attn.qkv.weight": 196608,
  "module.backbone.0.layers.1.blocks.1.attn.qkv.bias": 768,
  "module.backbone.0.layers.1.blocks.1.attn.proj.weight": 65536,
  "module.backbone.0.layers.1.blocks.1.attn.proj.bias": 256,
  "module.backbone.0.layers.1.blocks.1.norm2.weight": 256,
  "module.backbone.0.layers.1.blocks.1.norm2.bias": 256,
  "module.backbone.0.layers.1.blocks.1.mlp.fc1.weight": 262144,
  "module.backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1024,
  "module.backbone.0.layers.1.blocks.1.mlp.fc2.weight": 262144,
  "module.backbone.0.layers.1.blocks.1.mlp.fc2.bias": 256,
  "module.backbone.0.layers.1.downsample.reduction.weight": 524288,
  "module.backbone.0.layers.1.downsample.norm.weight": 1024,
  "module.backbone.0.layers.1.downsample.norm.bias": 1024,
  "module.backbone.0.layers.2.blocks.0.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.0.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.0.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.0.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.0.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.0.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.0.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.0.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.0.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.0.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.0.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.0.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.1.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.1.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.1.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.1.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.1.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.1.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.1.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.1.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.1.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.1.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.1.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.1.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.2.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.2.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.2.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.2.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.2.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.2.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.2.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.2.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.2.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.2.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.2.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.2.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.3.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.3.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.3.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.3.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.3.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.3.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.3.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.3.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.3.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.3.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.3.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.3.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.4.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.4.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.4.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.4.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.4.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.4.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.4.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.4.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.4.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.4.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.4.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.4.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.5.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.5.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.5.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.5.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.5.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.5.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.5.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.5.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.5.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.5.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.5.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.5.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.6.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.6.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.6.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.6.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.6.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.6.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.6.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.6.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.6.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.6.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.6.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.6.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.7.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.7.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.7.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.7.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.7.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.7.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.7.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.7.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.7.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.7.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.7.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.7.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.8.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.8.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.8.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.8.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.8.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.8.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.8.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.8.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.8.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.8.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.8.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.8.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.9.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.9.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.9.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.9.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.9.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.9.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.9.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.9.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.9.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.9.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.9.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.9.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.10.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.10.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.10.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.10.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.10.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.10.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.10.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.10.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.10.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.10.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.10.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.10.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.11.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.11.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.11.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.11.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.11.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.11.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.11.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.11.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.11.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.11.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.11.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.11.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.12.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.12.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.12.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.12.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.12.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.12.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.12.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.12.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.12.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.12.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.12.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.12.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.13.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.13.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.13.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.13.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.13.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.13.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.13.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.13.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.13.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.13.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.13.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.13.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.14.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.14.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.14.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.14.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.14.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.14.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.14.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.14.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.14.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.14.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.14.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.14.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.15.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.15.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.15.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.15.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.15.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.15.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.15.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.15.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.15.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.15.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.15.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.15.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.16.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.16.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.16.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.16.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.16.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.16.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.16.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.16.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.16.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.16.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.16.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.16.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.17.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.17.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.17.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.17.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.17.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.17.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.17.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.17.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.17.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.17.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.17.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.17.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.downsample.reduction.weight": 2097152,
  "module.backbone.0.layers.2.downsample.norm.weight": 2048,
  "module.backbone.0.layers.2.downsample.norm.bias": 2048,
  "module.backbone.0.layers.3.blocks.0.norm1.weight": 1024,
  "module.backbone.0.layers.3.blocks.0.norm1.bias": 1024,
  "module.backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 16928,
  "module.backbone.0.layers.3.blocks.0.attn.qkv.weight": 3145728,
  "module.backbone.0.layers.3.blocks.0.attn.qkv.bias": 3072,
  "module.backbone.0.layers.3.blocks.0.attn.proj.weight": 1048576,
  "module.backbone.0.layers.3.blocks.0.attn.proj.bias": 1024,
  "module.backbone.0.layers.3.blocks.0.norm2.weight": 1024,
  "module.backbone.0.layers.3.blocks.0.norm2.bias": 1024,
  "module.backbone.0.layers.3.blocks.0.mlp.fc1.weight": 4194304,
  "module.backbone.0.layers.3.blocks.0.mlp.fc1.bias": 4096,
  "module.backbone.0.layers.3.blocks.0.mlp.fc2.weight": 4194304,
  "module.backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1024,
  "module.backbone.0.layers.3.blocks.1.norm1.weight": 1024,
  "module.backbone.0.layers.3.blocks.1.norm1.bias": 1024,
  "module.backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 16928,
  "module.backbone.0.layers.3.blocks.1.attn.qkv.weight": 3145728,
  "module.backbone.0.layers.3.blocks.1.attn.qkv.bias": 3072,
  "module.backbone.0.layers.3.blocks.1.attn.proj.weight": 1048576,
  "module.backbone.0.layers.3.blocks.1.attn.proj.bias": 1024,
  "module.backbone.0.layers.3.blocks.1.norm2.weight": 1024,
  "module.backbone.0.layers.3.blocks.1.norm2.bias": 1024,
  "module.backbone.0.layers.3.blocks.1.mlp.fc1.weight": 4194304,
  "module.backbone.0.layers.3.blocks.1.mlp.fc1.bias": 4096,
  "module.backbone.0.layers.3.blocks.1.mlp.fc2.weight": 4194304,
  "module.backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1024,
  "module.backbone.0.norm1.weight": 256,
  "module.backbone.0.norm1.bias": 256,
  "module.backbone.0.norm2.weight": 512,
  "module.backbone.0.norm2.bias": 512,
  "module.backbone.0.norm3.weight": 1024,
  "module.backbone.0.norm3.bias": 1024
}[0m
[32mINFO    [0m [32m2025-10-24 01:53:41,548 | [34mparams after freezing:
{
  "module.transformer.level_embed": 1024,
  "module.transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.0.norm1.weight": 256,
  "module.transformer.encoder.layers.0.norm1.bias": 256,
  "module.transformer.encoder.layers.0.linear1.weight": 524288,
  "module.transformer.encoder.layers.0.linear1.bias": 2048,
  "module.transformer.encoder.layers.0.linear2.weight": 524288,
  "module.transformer.encoder.layers.0.linear2.bias": 256,
  "module.transformer.encoder.layers.0.norm2.weight": 256,
  "module.transformer.encoder.layers.0.norm2.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.1.norm1.weight": 256,
  "module.transformer.encoder.layers.1.norm1.bias": 256,
  "module.transformer.encoder.layers.1.linear1.weight": 524288,
  "module.transformer.encoder.layers.1.linear1.bias": 2048,
  "module.transformer.encoder.layers.1.linear2.weight": 524288,
  "module.transformer.encoder.layers.1.linear2.bias": 256,
  "module.transformer.encoder.layers.1.norm2.weight": 256,
  "module.transformer.encoder.layers.1.norm2.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.2.norm1.weight": 256,
  "module.transformer.encoder.layers.2.norm1.bias": 256,
  "module.transformer.encoder.layers.2.linear1.weight": 524288,
  "module.transformer.encoder.layers.2.linear1.bias": 2048,
  "module.transformer.encoder.layers.2.linear2.weight": 524288,
  "module.transformer.encoder.layers.2.linear2.bias": 256,
  "module.transformer.encoder.layers.2.norm2.weight": 256,
  "module.transformer.encoder.layers.2.norm2.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.3.norm1.weight": 256,
  "module.transformer.encoder.layers.3.norm1.bias": 256,
  "module.transformer.encoder.layers.3.linear1.weight": 524288,
  "module.transformer.encoder.layers.3.linear1.bias": 2048,
  "module.transformer.encoder.layers.3.linear2.weight": 524288,
  "module.transformer.encoder.layers.3.linear2.bias": 256,
  "module.transformer.encoder.layers.3.norm2.weight": 256,
  "module.transformer.encoder.layers.3.norm2.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.4.norm1.weight": 256,
  "module.transformer.encoder.layers.4.norm1.bias": 256,
  "module.transformer.encoder.layers.4.linear1.weight": 524288,
  "module.transformer.encoder.layers.4.linear1.bias": 2048,
  "module.transformer.encoder.layers.4.linear2.weight": 524288,
  "module.transformer.encoder.layers.4.linear2.bias": 256,
  "module.transformer.encoder.layers.4.norm2.weight": 256,
  "module.transformer.encoder.layers.4.norm2.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "module.transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "module.transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "module.transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "module.transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "module.transformer.encoder.layers.5.norm1.weight": 256,
  "module.transformer.encoder.layers.5.norm1.bias": 256,
  "module.transformer.encoder.layers.5.linear1.weight": 524288,
  "module.transformer.encoder.layers.5.linear1.bias": 2048,
  "module.transformer.encoder.layers.5.linear2.weight": 524288,
  "module.transformer.encoder.layers.5.linear2.bias": 256,
  "module.transformer.encoder.layers.5.norm2.weight": 256,
  "module.transformer.encoder.layers.5.norm2.bias": 256,
  "module.transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.0.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.0.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.0.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.0.linear2.bias": 256,
  "module.transformer.encoder.text_layers.0.norm1.weight": 256,
  "module.transformer.encoder.text_layers.0.norm1.bias": 256,
  "module.transformer.encoder.text_layers.0.norm2.weight": 256,
  "module.transformer.encoder.text_layers.0.norm2.bias": 256,
  "module.transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.1.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.1.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.1.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.1.linear2.bias": 256,
  "module.transformer.encoder.text_layers.1.norm1.weight": 256,
  "module.transformer.encoder.text_layers.1.norm1.bias": 256,
  "module.transformer.encoder.text_layers.1.norm2.weight": 256,
  "module.transformer.encoder.text_layers.1.norm2.bias": 256,
  "module.transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.2.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.2.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.2.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.2.linear2.bias": 256,
  "module.transformer.encoder.text_layers.2.norm1.weight": 256,
  "module.transformer.encoder.text_layers.2.norm1.bias": 256,
  "module.transformer.encoder.text_layers.2.norm2.weight": 256,
  "module.transformer.encoder.text_layers.2.norm2.bias": 256,
  "module.transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.3.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.3.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.3.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.3.linear2.bias": 256,
  "module.transformer.encoder.text_layers.3.norm1.weight": 256,
  "module.transformer.encoder.text_layers.3.norm1.bias": 256,
  "module.transformer.encoder.text_layers.3.norm2.weight": 256,
  "module.transformer.encoder.text_layers.3.norm2.bias": 256,
  "module.transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.4.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.4.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.4.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.4.linear2.bias": 256,
  "module.transformer.encoder.text_layers.4.norm1.weight": 256,
  "module.transformer.encoder.text_layers.4.norm1.bias": 256,
  "module.transformer.encoder.text_layers.4.norm2.weight": 256,
  "module.transformer.encoder.text_layers.4.norm2.bias": 256,
  "module.transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "module.transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "module.transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "module.transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "module.transformer.encoder.text_layers.5.linear1.weight": 262144,
  "module.transformer.encoder.text_layers.5.linear1.bias": 1024,
  "module.transformer.encoder.text_layers.5.linear2.weight": 262144,
  "module.transformer.encoder.text_layers.5.linear2.bias": 256,
  "module.transformer.encoder.text_layers.5.norm1.weight": 256,
  "module.transformer.encoder.text_layers.5.norm1.bias": 256,
  "module.transformer.encoder.text_layers.5.norm2.weight": 256,
  "module.transformer.encoder.text_layers.5.norm2.bias": 256,
  "module.transformer.encoder.fusion_layers.0.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.0.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.1.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.1.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.2.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.2.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.3.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.3.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.4.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.4.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.5.gamma_v": 256,
  "module.transformer.encoder.fusion_layers.5.gamma_l": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "module.transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "module.transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "module.transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "module.transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "module.transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.0.norm1.weight": 256,
  "module.transformer.decoder.layers.0.norm1.bias": 256,
  "module.transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.0.catext_norm.weight": 256,
  "module.transformer.decoder.layers.0.catext_norm.bias": 256,
  "module.transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.0.norm2.weight": 256,
  "module.transformer.decoder.layers.0.norm2.bias": 256,
  "module.transformer.decoder.layers.0.linear1.weight": 524288,
  "module.transformer.decoder.layers.0.linear1.bias": 2048,
  "module.transformer.decoder.layers.0.linear2.weight": 524288,
  "module.transformer.decoder.layers.0.linear2.bias": 256,
  "module.transformer.decoder.layers.0.norm3.weight": 256,
  "module.transformer.decoder.layers.0.norm3.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.1.norm1.weight": 256,
  "module.transformer.decoder.layers.1.norm1.bias": 256,
  "module.transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.1.catext_norm.weight": 256,
  "module.transformer.decoder.layers.1.catext_norm.bias": 256,
  "module.transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.1.norm2.weight": 256,
  "module.transformer.decoder.layers.1.norm2.bias": 256,
  "module.transformer.decoder.layers.1.linear1.weight": 524288,
  "module.transformer.decoder.layers.1.linear1.bias": 2048,
  "module.transformer.decoder.layers.1.linear2.weight": 524288,
  "module.transformer.decoder.layers.1.linear2.bias": 256,
  "module.transformer.decoder.layers.1.norm3.weight": 256,
  "module.transformer.decoder.layers.1.norm3.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.2.norm1.weight": 256,
  "module.transformer.decoder.layers.2.norm1.bias": 256,
  "module.transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.2.catext_norm.weight": 256,
  "module.transformer.decoder.layers.2.catext_norm.bias": 256,
  "module.transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.2.norm2.weight": 256,
  "module.transformer.decoder.layers.2.norm2.bias": 256,
  "module.transformer.decoder.layers.2.linear1.weight": 524288,
  "module.transformer.decoder.layers.2.linear1.bias": 2048,
  "module.transformer.decoder.layers.2.linear2.weight": 524288,
  "module.transformer.decoder.layers.2.linear2.bias": 256,
  "module.transformer.decoder.layers.2.norm3.weight": 256,
  "module.transformer.decoder.layers.2.norm3.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.3.norm1.weight": 256,
  "module.transformer.decoder.layers.3.norm1.bias": 256,
  "module.transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.3.catext_norm.weight": 256,
  "module.transformer.decoder.layers.3.catext_norm.bias": 256,
  "module.transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.3.norm2.weight": 256,
  "module.transformer.decoder.layers.3.norm2.bias": 256,
  "module.transformer.decoder.layers.3.linear1.weight": 524288,
  "module.transformer.decoder.layers.3.linear1.bias": 2048,
  "module.transformer.decoder.layers.3.linear2.weight": 524288,
  "module.transformer.decoder.layers.3.linear2.bias": 256,
  "module.transformer.decoder.layers.3.norm3.weight": 256,
  "module.transformer.decoder.layers.3.norm3.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.4.norm1.weight": 256,
  "module.transformer.decoder.layers.4.norm1.bias": 256,
  "module.transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.4.catext_norm.weight": 256,
  "module.transformer.decoder.layers.4.catext_norm.bias": 256,
  "module.transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.4.norm2.weight": 256,
  "module.transformer.decoder.layers.4.norm2.bias": 256,
  "module.transformer.decoder.layers.4.linear1.weight": 524288,
  "module.transformer.decoder.layers.4.linear1.bias": 2048,
  "module.transformer.decoder.layers.4.linear2.weight": 524288,
  "module.transformer.decoder.layers.4.linear2.bias": 256,
  "module.transformer.decoder.layers.4.norm3.weight": 256,
  "module.transformer.decoder.layers.4.norm3.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "module.transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "module.transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "module.transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "module.transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "module.transformer.decoder.layers.5.norm1.weight": 256,
  "module.transformer.decoder.layers.5.norm1.bias": 256,
  "module.transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "module.transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "module.transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "module.transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "module.transformer.decoder.layers.5.catext_norm.weight": 256,
  "module.transformer.decoder.layers.5.catext_norm.bias": 256,
  "module.transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "module.transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "module.transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "module.transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "module.transformer.decoder.layers.5.norm2.weight": 256,
  "module.transformer.decoder.layers.5.norm2.bias": 256,
  "module.transformer.decoder.layers.5.linear1.weight": 524288,
  "module.transformer.decoder.layers.5.linear1.bias": 2048,
  "module.transformer.decoder.layers.5.linear2.weight": 524288,
  "module.transformer.decoder.layers.5.linear2.bias": 256,
  "module.transformer.decoder.layers.5.norm3.weight": 256,
  "module.transformer.decoder.layers.5.norm3.bias": 256,
  "module.transformer.decoder.norm.weight": 256,
  "module.transformer.decoder.norm.bias": 256,
  "module.transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "module.transformer.decoder.ref_point_head.layers.0.bias": 256,
  "module.transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "module.transformer.decoder.ref_point_head.layers.1.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "module.transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "module.transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "module.transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "module.transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "module.transformer.tgt_embed.weight": 230400,
  "module.transformer.enc_output.weight": 65536,
  "module.transformer.enc_output.bias": 256,
  "module.transformer.enc_output_norm.weight": 256,
  "module.transformer.enc_output_norm.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "module.transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "module.transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "module.transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "module.transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "module.feat_map.weight": 196608,
  "module.feat_map.bias": 256,
  "module.input_proj.0.0.weight": 65536,
  "module.input_proj.0.0.bias": 256,
  "module.input_proj.0.1.weight": 256,
  "module.input_proj.0.1.bias": 256,
  "module.input_proj.1.0.weight": 131072,
  "module.input_proj.1.0.bias": 256,
  "module.input_proj.1.1.weight": 256,
  "module.input_proj.1.1.bias": 256,
  "module.input_proj.2.0.weight": 262144,
  "module.input_proj.2.0.bias": 256,
  "module.input_proj.2.1.weight": 256,
  "module.input_proj.2.1.bias": 256,
  "module.input_proj.3.0.weight": 2359296,
  "module.input_proj.3.0.bias": 256,
  "module.input_proj.3.1.weight": 256,
  "module.input_proj.3.1.bias": 256,
  "module.backbone.0.patch_embed.proj.weight": 6144,
  "module.backbone.0.patch_embed.proj.bias": 128,
  "module.backbone.0.patch_embed.norm.weight": 128,
  "module.backbone.0.patch_embed.norm.bias": 128,
  "module.backbone.0.layers.0.blocks.0.norm1.weight": 128,
  "module.backbone.0.layers.0.blocks.0.norm1.bias": 128,
  "module.backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 2116,
  "module.backbone.0.layers.0.blocks.0.attn.qkv.weight": 49152,
  "module.backbone.0.layers.0.blocks.0.attn.qkv.bias": 384,
  "module.backbone.0.layers.0.blocks.0.attn.proj.weight": 16384,
  "module.backbone.0.layers.0.blocks.0.attn.proj.bias": 128,
  "module.backbone.0.layers.0.blocks.0.norm2.weight": 128,
  "module.backbone.0.layers.0.blocks.0.norm2.bias": 128,
  "module.backbone.0.layers.0.blocks.0.mlp.fc1.weight": 65536,
  "module.backbone.0.layers.0.blocks.0.mlp.fc1.bias": 512,
  "module.backbone.0.layers.0.blocks.0.mlp.fc2.weight": 65536,
  "module.backbone.0.layers.0.blocks.0.mlp.fc2.bias": 128,
  "module.backbone.0.layers.0.blocks.1.norm1.weight": 128,
  "module.backbone.0.layers.0.blocks.1.norm1.bias": 128,
  "module.backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 2116,
  "module.backbone.0.layers.0.blocks.1.attn.qkv.weight": 49152,
  "module.backbone.0.layers.0.blocks.1.attn.qkv.bias": 384,
  "module.backbone.0.layers.0.blocks.1.attn.proj.weight": 16384,
  "module.backbone.0.layers.0.blocks.1.attn.proj.bias": 128,
  "module.backbone.0.layers.0.blocks.1.norm2.weight": 128,
  "module.backbone.0.layers.0.blocks.1.norm2.bias": 128,
  "module.backbone.0.layers.0.blocks.1.mlp.fc1.weight": 65536,
  "module.backbone.0.layers.0.blocks.1.mlp.fc1.bias": 512,
  "module.backbone.0.layers.0.blocks.1.mlp.fc2.weight": 65536,
  "module.backbone.0.layers.0.blocks.1.mlp.fc2.bias": 128,
  "module.backbone.0.layers.0.downsample.reduction.weight": 131072,
  "module.backbone.0.layers.0.downsample.norm.weight": 512,
  "module.backbone.0.layers.0.downsample.norm.bias": 512,
  "module.backbone.0.layers.1.blocks.0.norm1.weight": 256,
  "module.backbone.0.layers.1.blocks.0.norm1.bias": 256,
  "module.backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 4232,
  "module.backbone.0.layers.1.blocks.0.attn.qkv.weight": 196608,
  "module.backbone.0.layers.1.blocks.0.attn.qkv.bias": 768,
  "module.backbone.0.layers.1.blocks.0.attn.proj.weight": 65536,
  "module.backbone.0.layers.1.blocks.0.attn.proj.bias": 256,
  "module.backbone.0.layers.1.blocks.0.norm2.weight": 256,
  "module.backbone.0.layers.1.blocks.0.norm2.bias": 256,
  "module.backbone.0.layers.1.blocks.0.mlp.fc1.weight": 262144,
  "module.backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1024,
  "module.backbone.0.layers.1.blocks.0.mlp.fc2.weight": 262144,
  "module.backbone.0.layers.1.blocks.0.mlp.fc2.bias": 256,
  "module.backbone.0.layers.1.blocks.1.norm1.weight": 256,
  "module.backbone.0.layers.1.blocks.1.norm1.bias": 256,
  "module.backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 4232,
  "module.backbone.0.layers.1.blocks.1.attn.qkv.weight": 196608,
  "module.backbone.0.layers.1.blocks.1.attn.qkv.bias": 768,
  "module.backbone.0.layers.1.blocks.1.attn.proj.weight": 65536,
  "module.backbone.0.layers.1.blocks.1.attn.proj.bias": 256,
  "module.backbone.0.layers.1.blocks.1.norm2.weight": 256,
  "module.backbone.0.layers.1.blocks.1.norm2.bias": 256,
  "module.backbone.0.layers.1.blocks.1.mlp.fc1.weight": 262144,
  "module.backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1024,
  "module.backbone.0.layers.1.blocks.1.mlp.fc2.weight": 262144,
  "module.backbone.0.layers.1.blocks.1.mlp.fc2.bias": 256,
  "module.backbone.0.layers.1.downsample.reduction.weight": 524288,
  "module.backbone.0.layers.1.downsample.norm.weight": 1024,
  "module.backbone.0.layers.1.downsample.norm.bias": 1024,
  "module.backbone.0.layers.2.blocks.0.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.0.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.0.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.0.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.0.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.0.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.0.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.0.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.0.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.0.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.0.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.0.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.1.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.1.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.1.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.1.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.1.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.1.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.1.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.1.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.1.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.1.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.1.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.1.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.2.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.2.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.2.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.2.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.2.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.2.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.2.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.2.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.2.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.2.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.2.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.2.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.3.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.3.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.3.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.3.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.3.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.3.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.3.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.3.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.3.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.3.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.3.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.3.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.4.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.4.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.4.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.4.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.4.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.4.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.4.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.4.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.4.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.4.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.4.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.4.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.5.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.5.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.5.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.5.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.5.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.5.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.5.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.5.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.5.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.5.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.5.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.5.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.6.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.6.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.6.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.6.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.6.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.6.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.6.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.6.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.6.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.6.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.6.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.6.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.7.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.7.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.7.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.7.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.7.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.7.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.7.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.7.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.7.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.7.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.7.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.7.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.8.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.8.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.8.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.8.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.8.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.8.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.8.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.8.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.8.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.8.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.8.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.8.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.9.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.9.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.9.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.9.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.9.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.9.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.9.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.9.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.9.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.9.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.9.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.9.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.10.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.10.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.10.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.10.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.10.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.10.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.10.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.10.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.10.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.10.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.10.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.10.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.11.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.11.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.11.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.11.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.11.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.11.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.11.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.11.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.11.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.11.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.11.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.11.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.12.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.12.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.12.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.12.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.12.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.12.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.12.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.12.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.12.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.12.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.12.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.12.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.13.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.13.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.13.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.13.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.13.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.13.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.13.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.13.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.13.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.13.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.13.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.13.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.14.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.14.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.14.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.14.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.14.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.14.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.14.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.14.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.14.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.14.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.14.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.14.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.15.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.15.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.15.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.15.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.15.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.15.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.15.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.15.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.15.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.15.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.15.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.15.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.16.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.16.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.16.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.16.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.16.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.16.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.16.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.16.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.16.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.16.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.16.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.16.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.blocks.17.norm1.weight": 512,
  "module.backbone.0.layers.2.blocks.17.norm1.bias": 512,
  "module.backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 8464,
  "module.backbone.0.layers.2.blocks.17.attn.qkv.weight": 786432,
  "module.backbone.0.layers.2.blocks.17.attn.qkv.bias": 1536,
  "module.backbone.0.layers.2.blocks.17.attn.proj.weight": 262144,
  "module.backbone.0.layers.2.blocks.17.attn.proj.bias": 512,
  "module.backbone.0.layers.2.blocks.17.norm2.weight": 512,
  "module.backbone.0.layers.2.blocks.17.norm2.bias": 512,
  "module.backbone.0.layers.2.blocks.17.mlp.fc1.weight": 1048576,
  "module.backbone.0.layers.2.blocks.17.mlp.fc1.bias": 2048,
  "module.backbone.0.layers.2.blocks.17.mlp.fc2.weight": 1048576,
  "module.backbone.0.layers.2.blocks.17.mlp.fc2.bias": 512,
  "module.backbone.0.layers.2.downsample.reduction.weight": 2097152,
  "module.backbone.0.layers.2.downsample.norm.weight": 2048,
  "module.backbone.0.layers.2.downsample.norm.bias": 2048,
  "module.backbone.0.layers.3.blocks.0.norm1.weight": 1024,
  "module.backbone.0.layers.3.blocks.0.norm1.bias": 1024,
  "module.backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 16928,
  "module.backbone.0.layers.3.blocks.0.attn.qkv.weight": 3145728,
  "module.backbone.0.layers.3.blocks.0.attn.qkv.bias": 3072,
  "module.backbone.0.layers.3.blocks.0.attn.proj.weight": 1048576,
  "module.backbone.0.layers.3.blocks.0.attn.proj.bias": 1024,
  "module.backbone.0.layers.3.blocks.0.norm2.weight": 1024,
  "module.backbone.0.layers.3.blocks.0.norm2.bias": 1024,
  "module.backbone.0.layers.3.blocks.0.mlp.fc1.weight": 4194304,
  "module.backbone.0.layers.3.blocks.0.mlp.fc1.bias": 4096,
  "module.backbone.0.layers.3.blocks.0.mlp.fc2.weight": 4194304,
  "module.backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1024,
  "module.backbone.0.layers.3.blocks.1.norm1.weight": 1024,
  "module.backbone.0.layers.3.blocks.1.norm1.bias": 1024,
  "module.backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 16928,
  "module.backbone.0.layers.3.blocks.1.attn.qkv.weight": 3145728,
  "module.backbone.0.layers.3.blocks.1.attn.qkv.bias": 3072,
  "module.backbone.0.layers.3.blocks.1.attn.proj.weight": 1048576,
  "module.backbone.0.layers.3.blocks.1.attn.proj.bias": 1024,
  "module.backbone.0.layers.3.blocks.1.norm2.weight": 1024,
  "module.backbone.0.layers.3.blocks.1.norm2.bias": 1024,
  "module.backbone.0.layers.3.blocks.1.mlp.fc1.weight": 4194304,
  "module.backbone.0.layers.3.blocks.1.mlp.fc1.bias": 4096,
  "module.backbone.0.layers.3.blocks.1.mlp.fc2.weight": 4194304,
  "module.backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1024,
  "module.backbone.0.norm1.weight": 256,
  "module.backbone.0.norm1.bias": 256,
  "module.backbone.0.norm2.weight": 512,
  "module.backbone.0.norm2.bias": 512,
  "module.backbone.0.norm3.weight": 1024,
  "module.backbone.0.norm3.bias": 1024
}[0m
[36mDEBUG   [0m [36m2025-10-24 01:53:41,549 | [34mbuild dataset ... ...[0m
../vlmtest/GroundingDINO/dataset/kitti/training/image_02 ../vlmtest/GroundingDINO/dataset/kitti/training/kitti_odvg.jsonl ../vlmtest/GroundingDINO/dataset/kitti/label_map_odvg.json
  == total images: 4841
  == total labels: 2
[36mDEBUG   [0m [36m2025-10-24 01:53:41,636 | [34mbuild dataset, done.[0m
[36mDEBUG   [0m [36m2025-10-24 01:53:41,636 | [34mnumber of training dataset: 1, samples: 4841[0m
../vlmtest/GroundingDINO/dataset/kitti/validation/image_02 ../vlmtest/GroundingDINO/dataset/kitti/validation/val_kitti.json
loading annotations into memory...
Done (t=0.04s)
creating index...
index created!
Start training
